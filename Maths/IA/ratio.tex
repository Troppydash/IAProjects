\documentclass[a4paper,11pt]{article}
\usepackage[a4paper,margin=1in,footskip=0.25in]{geometry}
\usepackage[utf8]{inputenc}

% science
\usepackage{amsmath}
\usepackage{array}
\usepackage{siunitx}

% code
% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{10} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{10}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
        language=Python,
        basicstyle=\ttm,
        morekeywords={self},              % Add keywords here
        keywordstyle=\ttb\color{deepblue},
        emph={MyClass,__init__},          % Custom highlighting
        emphstyle=\ttb\color{deepred},    % Custom highlighting style
        stringstyle=\color{deepgreen},
        frame=tb,                         % Any extra options here
        showstringspaces=false
}}


% Python environment
\lstnewenvironment{python}[1][]
{
    \pythonstyle
    \lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
        \pythonstyle
        \lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

% layout
\usepackage{float}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{circuitikz}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage[export]{adjustbox}
\usepackage{hhline}

% referencing
\usepackage[style=apa]{biblatex}
\addbibresource{ratio.bib}

% table centering
\renewcommand{\arraystretch}{1.3}
\newcolumntype{P}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcommand{\tptt}{$\times\,$}

% figures labelings
\usepackage{chngcntr}
\counterwithin{figure}{section}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}

% fancy page numbers
\usepackage{fancyhdr}
% bottom right
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[R]{Page \thepage}
\fancypagestyle{plain}{%
    \renewcommand{\headrulewidth}{0pt}%
    \fancyhf{}%
    \fancyfoot[R]{Page \thepage}%
}
%go
\renewcommand{\headrulewidth}{0pt}

\usepackage{hyperref}

\title{\vspace{-8ex}Estimating the quality of YouTube videos based on its likes and dislikes}

\author{Terry Qi}
\date{}
%\date{\vspace{-8ex}}

\begin{document}

% Planning
% Introduction
% Definition
% Steps of exploration
% Simulation Approach
% Statistical Approach
% Bayensian Approach
% Conclusion




\maketitle

\section{Introduction}

\begin{wrapfigure}{r}{0.45\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{assets/som1.png}
    \caption{The SoME1 event}
    \label{fig:some1}
\end{wrapfigure}

The topic of my exploration originates from a personal need I've developed in the school holidays.

I am familiar with the maths channel 3Blue1Brown (3B1B) on YouTube through a self learning playlist on the topic of linear algebra in year 1 IB, and was patiently waiting for a new video for it is the holidays. When Grant (owner of 3B1B) announced a contest (figure \ref{fig:some1}) not long after encouraging amateur video makers to share their hidden maths knowledges, I was understandably very excited to have my entire YouTube home page filled with the new maths videos. While I did find some brilliantly made videos like ``\href{https://www.youtube.com/watch?v=aVwxzDHniEw}{The Beauty of B\'{e}zier Curves}'' by Freya Holm\'{e}r, and an explanation of ``\href{https://www.youtube.com/watch?v=78wz4KSzUvo}{Noether's Theorem}'' by Orla M, I quickly realized my inability to view all of the thousands of videos within a two week holiday. The solution? I will only watch the best ones.

But how do you tell if a YouTube video is the ``best'' out of the bunch? Visual indicators like interesting thumbnails may be attempting, but one should really not judge the book by its cover; while comparing view counts is fast, it is against the purpose of the maths event --- to discover new talented video creators. So I am left with the only other numerical indicators, to judge the quality of the video through the amount of likes and dislikes it has. While this measure have its limitations: the internet audience is biased in political and social values, it is certainty the most interesting metric.

%(At the time of writing, the company YouTube has removed the dislike count on all videos, which is disappointing)

Therefore within this exploration, I will be finding an equation relating the amount of likes and dislikes a YouTube video has to the best estimate of its perceived quality by the viewers. I will be using multiple methods such as simulations, statistical distributions, and a Bayesian approach to deduce the relationships between the two variables. It will be crucial that I evaluate the pros and cons of each approach, both in its solution but also in its derivation, and use my knowledge to rank five videos from the SoME1 event (table \ref{tbl:videos}, appendix).
%\begin{wrapfigure}{r}{0.4\textwidth}
%    \centering
%    \includegraphics[width=0.45\textwidth]{assets/intro.png}
%    \caption{Hidden Dislikes}
%    \label{fig:hidden}
%\end{wrapfigure}

%This topic is chosen out of my curiously towards a very insignificant change. For I often procrastinate when doing my homework, I stumbled across a post on an online forum announcing the the popular internet video sharing platform of YouTube of removing their dislike counts (shown in Figure \ref{fig:hidden}). As usual, I dug into the comment section of the announcement and saw all the various complaints that one will expect on the internet, all but one has caught my eye:

%\begin{quote}
%    Dislike counts were necessary to spot clickbait, scams, fake tutorials, blatant misinformation, etc. --- Element 115 (internet user)
%\end{quote}

%The usage of likes and dislikes as a metric of legibility and quality is something that I knew and used extensively, mostly in saving my precious time in judging the qualities of the a series of maths videos made for the trend ``Summer of Math Exposition'' (SoME1) consisting of mostly amateur video makers. While the removal of the dislike counts demonstrated on how reliant I was on a simple number, it also led me to wonder of my technique in judging the quality of a video, especially in the SoME1 series for the like and dislike counts are often low. Therefore I felt this topic is worth exploring for its practicality.

% aim here

% 5 videos
% https://www.youtube.com/watch?v=-LVhZtFwZzM
% 705 2
% https://www.youtube.com/watch?v=E9IQY8LzzO8
% 35 5
% https://www.youtube.com/watch?v=vc_-aCeP7y8
% 25 0
% https://www.youtube.com/watch?v=tc53eCUvJyY
% 15 0 756
% https://www.youtube.com/watch?v=TJyCbR29Mds
% 4 0 138

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Views & 138 & 440 & 467 & 756 & 10907 \\
        \hline
        Likes & 4 & 25 & 34 & 15 & 705 \\
        \hline
        Dislikes & 0 & 0 & 5 & 0 & 2
    \end{tabular}
    \captionof{table}{}
    \label{tbl:videos}
\end{figure}


\section{Keywords}

First we have to define some keywords which are used from this point onward. All YouTube videos are referred to as videos; the \textbf{ratings} of a video are its likes and dislikes, which are both positive integers; the \textbf{likeability} is the metric used to convey the quality of a video, and is defined as a probability between 0 and 1, representing the mean probability of a viewer rating the video to select ``like''. (For example, a likeability of $0.5$ means that on average, a person rating the video is pressing the like button 50\% of the time) The focus would be to find a mathematical definition of this likeability.

To showcase an initial attempt at defining this value, consider the two following videos:

% the two videos
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/s_vid2.png}
    \caption{Video one}
    \label{fig:vid1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/s_vid1.png}
    \caption{Video two}
    \label{fig:vid2}
\end{figure}

Figure \ref{fig:vid1} is a video with 6 likes and 1 dislike. Figure \ref{fig:vid2} is a video with 23 likes and 4 dislikes. Naively, it is tempting to calculate the likeabilities ($L_n$) of the two videos by dividing the amount of likes ($x$) against the total amount of ratings ($n$). This will be called as the \textbf{naive likeability}, and is defined by:

\[
L_n = \frac{x}{n}.
\]

The naive likeabilities of video one ($L_1$) and video two ($L_2$) are thus as follow:
\begin{align*}
    L_{1} &= \frac{6}{6+1} \approx 0.857, \,\, L_{2} = \frac{23}{23 + 4} \approx 0.851.
\end{align*}

If we assume this naive mathematical definition of the likeabilities represents our language definition, then we can rate the first video higher than the second because it has a higher likeability ($0.857 > 0.851$). So we should watch video one first, right?

However, the calculations are unlikely to match our proper definitions of likeability, simply because they failed to take the total amount of ratings into consideration. While video one has a higher like to dislike ratio than video two, there are fundamentally less overall ratings available. Thus our method also needs to factor in the amount of information we can see, to include a factor of certainty, almost.

This can be illustrated with an example taken to the extreme. A video with only one like and zero dislikes have a naive likeability of 100\%, but can we really be sure that it is of a higher quality than a video with 1000 likes and 1 dislike (naive likeability of 99.9\%)?

Therefore the naive likeability definition is uninclusive of all information but is fast. Nevertheless, table \ref{tbl:naive} shows the five videos as ranked by their naive likeabilities.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Naive Likeability (3dp) & 1.000 & 1.000 & 0.872 & 1.000 & 0.997
    \end{tabular}
    \captionof{table}{}
    \label{tbl:naive}
\end{figure}


\section{Simulation}
For any statistical or probabilistic question, it is always helpful to start with a simulation of some kind. This is because a simulation allows me to both describe the problem as well as to approach a numerical solution, guaranteed by the law of large numbers --- stating that the statistical descriptions of a sample will tend towards that of the true descriptions as sample size increases.

% description of what I did
To do this, I've used Python 3.7 to write a small piece of code that does the calculations, and used a Python library called Matplotlib to graph the numbers.

Using video one (6 likes and 1 dislike) as an example, notice that it is theoretically possible for the video likeability to be of any probability except 0 and 1, for there is still a non-zero probability of receiving 6 likes on a video with 1\% likability, albeit very unlikely. Therefore I thought to define the likeability of a video by the average of all the possible likeabilities weighted by how likely they are to occur, as it matches our literal definition of ``the mean probability of a viewer rating the video to select like''.

The pseudocode for our simulation will look as follow:

\begin{python}
1   weighted = 0
2   for likeability in 0..1:
3       occurrence = simulate_occurence(likeability)
4
5       weighted += likeability * occurence / sample_size
6       plot(likeability, occurence)
\end{python}

The breakdown of this piece of code is as follows:

I first defined a variable \pythoninline{weighted} to hold the weighted average of the likeabilties:

\begin{python}
1   weighted = 0
\end{python}

Then I loop over all possible likeabilities from 0 to 1 using a \textit{for in} loop:
\begin{python}
2   for likeability in 0..1:
\end{python}

For each likability, I considered a simulation of 1000 times a group of 7 people rating the video. This is performed in the function \pythoninline{simulate_occurence}(appendix), which takes the likeability as an input. It outputs the \# of times the ratings by those 7 people matches the 6 likes and 1 dislike of video one, and saves this in the variable called \pythoninline{occurrence}.

\begin{python}
3       occurrence = simulate_occurence(likability)
\end{python}

To calculate the weighted averages (statistical mean) of the likeability, I've used the discrete mean formula, which states the mean ($\mu$) is the sum of the likeabilities ($L_i$) multiplied by their respective probabilities ($f(L_i)$):
\[
    \mu = \sum_{i = 1}^{n} L_i f(L_i)
\]

The probabilities of each possible likeability is computed in the simulate as the total occurence divided by the \pythoninline{sample_size} of 1000. This summation is reflected by adding each weighted likeability to the \pythoninline{weighted} variable for each possible likeability:

\begin{python}
5       weighted += likeability * occurence / sample_size
\end{python}

Finally I decided to plot this relationship between \pythoninline{occurence} against \pythoninline{likeability}. This is done by the \pythoninline{plot} function imported from Matplotlib:

\begin{python}
6       plot(likeability, occurence)
\end{python}

% optional
%\newpage

\begin{wrapfigure}{r}{0.47\textwidth}
    \includegraphics[width=0.44\textwidth,right]{assets/sim_ratings_v1.png}
    \caption{}
    \label{fig:sim_ratings_v1}
\end{wrapfigure}

To see the output, I ran the program with the parameters of 6 likes and 1 dislike from video one, and 1000 samples later I was greeted with the summary graph in figure \ref{fig:sim_ratings_v1}.

The blue dots in figure \ref{fig:sim_ratings_v1} represents the simulated occurence of the video ratings out of 1000 samples of a chosen likeability (the likeabilities are selected with steps of 0.05 for clarity). The red vertical line graphs the mean likeability.

The graph was both an expected and unexpected turnout. The simulation placed the likeability of video at $0.776$, this is expected for there are certainly very little information available in only 7 ratings, but unexpected in size of the difference ($0.857-0.776=0.081$) against the naive likeability of 0.857. This shows that the naive likeability greatly overvalued the true likeability of the video.

\begin{wrapfigure}{r}{0.47\textwidth}
    \includegraphics[width=0.44\textwidth,right]{assets/sim_ratings_v2.png}
    \caption{}
    \label{fig:sim_ratings_v2}
\end{wrapfigure}


By running the program with the parameters of the second video with 23 likes and 4 dislikes,
we obtain a mean of $0.828$ and figure \ref{fig:sim_ratings_v2}.

In comparison with its naive likeability, video two is less affected by the lack of information for the simulated likeability has much smaller difference ($0.851-0.828=0.023$) than we've seen in video one. This maybe imply (appendix table) that the naive likeability increases in accuracy the more information we have, which presents an extra requirement for our analytic solution later on.

The shape of the graphs, or more formally, distributions of the likeabilities are also worth noting. They very much resemble a hill shaped curve that has a peek at only one likeability, and slopes increasing shallower the further away from the peek. Interestingly, the chosen metric of the statistical mean does not reflect the peek of the curve --- the red line does not intersect at the top of the curve. I believe this has to do with the long tail of zero occurrences at lower likeabilities, for they decreases the statistical mean in calculations.

% conclusion
Therefore the simulation approach had prove to be helpful in framing the question in finding the so called statistical mean of the range of possible likeabilities, and on top of that, had created a numerical approach of estimating the likeability of videos. But it does come at a cost of accuracy and computational time, making the method unreliable and expensive to scale up to higher amounts of ratings. Table \ref{tbl:simulation} lists the five videos and their simulated likeability values with a sample size of 1000, and step 0.01.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Simulated Likeability (3dp) & 0.828 & 0.958 &  0.853 & 0.937 & 0.987
    \end{tabular}
    \captionof{table}{}
    \label{tbl:simulation}
\end{figure}

\section{Statistical}

% what are distributions
To search for a analytic (of symbols and operations) equation of the likeability metric, we must expand the idea of distributions that was touched on during simulations. Remember that the simulation was used to compute the occurrences of a given rating for all ranges of likeabilities, and the statistical mean of the curve it creates is the simulated likeability of the video. It may be helpful to define this curve more mathematically without the element of chance.

% examples of distributions
Firstly, the likeability of a video can be thought of as a \textbf{random variable} of symbol $L$. A statistical random variable represents uncertainty in a measurement of its domains --- the range of values the random variable could be.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/discrete_uniform_pdfs.png}
    \caption{}
    \label{fig:discrete_uniform}
\end{wrapfigure}

Consider rolling a regular six sided dice. The side facing up after a roll can take the values from 1 to 6, inclusive, represented by a random variable say $X$. Notice that unless the dice was biased, there is no reason to assume that one value is more probable than the other. In other words, each value of the range of possible values have equal probability of occurrence, precisely $\frac{1}{6}$. The probability can be represented as a distribution as in figure \ref{fig:discrete_uniform}.

The probability distribution of the random variable $X$ can also be denoted as a discrete uniform distribution. Discrete meaning the domain is of countable size; uniform meaning that all possible values have the same probability.

More formally, the distribution is also defined by its probability function, which is a function mapping a possible value to its chance of occurence. For our random variable $X$, its probability function $f(X_i)$ is simply:

\[
    f(X_i) = \frac{1}{6}
\]

%But our random variable of likeability does not have a finite domain, I hear you say. The random variable $L$ has infinite values it could take, ranging from zero to one. Thankfully, we can extend our discrete distribution to a continuous distribution.

To extend from a discrete distribution to a continuous distribution, consider a viewer's opinion on a video before they've seen the ratings. The likeability $L$ of the video will range continuously from zero to one, but unless the viewer has had a bad day, there is no reason to prefer a range of likeabilities to another. That is, chance of a specific likeability value is the same as any other value.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/uniform_pdfs.png}
    \caption{}
    \label{fig:uniform}
\end{wrapfigure}

However, the y-axis of probabilities must be switched to probably densities, because it is no longer accurate to talk about a specific value's probability --- we must now consider the probability of a range of values instead. The area under the probability distribution must also be of value one for normalization. Therefore, the initial probability distribution is displayed in figure \ref{fig:uniform}, with a probability density function $f(L)$ of:

\[
    f(L) = 1
\]

The concept of continuous distribution restricts the probability distribution of our likeability metric. It can be defined as a probability density function $f(L)$, with an area of one.

% the binominal
Using the ratings of video one as an example (6 likes and 1 dislike), consider a single likeability value from the domain of the random likeability variable $L$, say 0.5. What is the probability we see the ratings of video one with a true likeability of 50\%? Another distribution models this kind of scenario.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/bino_pdfs.png}
    \caption{}
    \label{fig:bino}
\end{wrapfigure}

The binomial distribution is a probability distribution that summarizes the likelihood that a value will take one of two independent values under a given success chance and assumptions (modified citation). In short, the distribution will model the distribution of the number of likes in a sample of ratings given a true likeability. It is a discrete distribution, and its discrete probability distribution function $f(x)$ is of the form:
\[
    f(x) = {n \choose x} p^x (1-p)^{n-x},
\]
where $n$ is the amount of ratings, and $p$ is the true likeability of the video. When graphed using the parameters of video one, the distribution resembles to that of figure \ref{fig:bino}.

While the distribution displays all the possible likes/dislikes combinations, the value that is of interest is colored in red. The figure describes the probability of getting 6 likes in 7 ratings as about 0.05, or 5\%. Or as a single calculation:
\[
    f(6) = {7 \choose 6} (0.5)^6 (1-0.5)^{7-6} \approx 0.05
\]
Therefore for each likeability of our random variable $L$, its probability is $f(6)$ with the variable $p$ replaced by the likeability. Therefore I was able to guess the probability density function $G(l)$ of our random variable as so (where $l$ are the range of likeabilities):
\[
    G(l) = {n \choose x} l^x (1-l)^{n-x} = {7 \choose 6} l^6 (1-l) ^{7-1}
\]
When graphed on a software, the likeability distribution looks like the left graph of figure \ref{fig:beta}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{assets/beta_pdfs.png}
    \caption{}
    \label{fig:beta}
\end{figure}

The curve plotted by $G(l)$ has a tail towards the left, with a singular peek near the value $0.85$. But the figure shows that it has an area of only $0.12$, which does not fit the requirement of a probability density function (of area one). I attempted to normalize this distribution by dividing it by its area $A$, that is:
\begin{align*}
    A &= \int_{0}^{1} G(l) \, dl\\
    &= \int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl\\
    &\approx 0.12
\end{align*}
Thus I was able to construct the normalized probability density function $K(l)$ for the likeability random variable (shown by the right graph of figure \ref{fig:beta}):
\begin{align*}
    K(l) &= \frac{G(l)}{A}\\
    &= \frac{ {n \choose x} l^x (1-l)^{n-x}} {\int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl}
\end{align*}
We are now able to take the statistical mean $\mu$ of this function, which would be the statistical solution of the estimated likeability of the video. Notice that we can restrict the integral bounds for the probability density function is only defined between 0 to 1:
\begin{align*}
    \mu &= \int_{-\infty}^{\infty} l K(l) \, dl\\
    &=\int_{0}^{1} l K(l) \, dl\\
    &=\int_{0}^{1} l \frac{ {n \choose x} l^x (1-l)^{n-x}} {\int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl} \, dl
\end{align*}
While I was able to reduce the complexity of this integral by canceling the choose function and combining the exponents, the remain integral seems unsolvable to any integration method I know:
\begin{align*}
    \mu &=\int_{0}^{1} \frac{ l^{x+1} (1-l)^{n-x}} {\int_{0}^{1} l^x (1-l)^{n-x} \, dl} \, dl\\
    &= \frac{1}{\int_{0}^{1} l^x (1-l)^{n-x} \, dl} \int_{0}^{1}  l^{x+1} (1-l)^{n-x} \, dl
\end{align*}
Thankfully, the internet was able to provide me a solution via a special function named the Beta function $B(x,y)$ and its relative the Gamma function $\Gamma(z)$(citation, wikipedia), which are defined as:
\begin{align*}
    B(x, y) &= \int_{0}^{1} l^{x-1} (1-l)^{y-1} dl\\
    \Gamma(z) &= \int_{0}^{\infty} x^{z-1} e^{-x} \, dx
\end{align*}
To put it simply, the Gamma function is a analytic continuation of the factorial operation --- meaning that it generalizes the factorial operation outside the positive integers. It has two relevant identities. The first stating its relation with the factorial operation, the second showing its identity with the Beta function.
\begin{align*}
    \Gamma(z) &= (z-1)!\\
    B(x, y) &= \frac{\Gamma(x) \Gamma(y)}{\Gamma(x + y)}
\end{align*}
I was able to simplify the formula for the statistical mean using the Beta function, which can be converted to a series of Gamma functions and therefore factorials:
\begin{align*}
    \mu &= \frac{1}{B(x+2, n-x+1)}B(x+1, n-x+1)\\
    &= \frac{\frac{\Gamma(x+2)\Gamma(n-x+1)}{\Gamma(n+3)}}{\frac{\Gamma(x+1)\Gamma(n-x+1)}{\Gamma(n+2)}} =  \frac{\frac{(x+1)!(n-x)!}{(n+2)!}}{\frac{x!(n-x)!}{(n+1)!}}\\
    &= \frac{x+1}{n+2} = \frac{6+1}{7+2} \approx 0.778
\end{align*}
It was surprising how neat the final solution was given the complexity that is the integral before. Furthermore, this shows that the statistical likeability of the video can be calculated by dividing the amount of likes plus one over the amount of ratings plus two, under the assumption that the initial likeability distribution was uniform.

The small differences between the statistical method and the simulation method ($|0.776 - 0.778| = 0.002 \approx 2.58\%$) showcases both the correctness of our solution, but it also illustrates the power of simulations --- I did not have to do any maths to get an approximate answer. Additionally, the neat solution explains the validity of the naive method at large rating numbers, for the pluses become insignificant as their operands increases.

Overall, the statistical method required a reasonable amount of statistical knowledge, and I was greatly assisted by the use of a computer program in checking the equalities between each simplifying step. However, it produced a tidy result that is easy to remember and fast to compute. Table \ref{tbl:stat} lists the five videos ranked by their statistical likeability.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Statistical Likeability (3dp) & 0.833 & 0.926 & 0.854 & 0.941 & 0.994
    \end{tabular}
    \captionof{table}{}
    \label{tbl:stat}
\end{figure}

\section{Bayesian}

The premise of this section was hinted upon within the statistical analysis of the probability distribution of the likeability random variable. While it is often reasonable to accept a perfectly uniform distribution as the initial distribution of the likeability before seeing the rating, it may not be desirable in ranking the videos YouTube recommended to me, for they are very unlikely to be of low likeability before I even see their ratings. While these external factors are difficult to capture in traditional statistical distribution analysis, it is the core idea in a branch of statistics, Bayesian statistics.

% frequenist, bayesian
The core principles in the two branches of statistics differs in their interpretations of probabilities. The frequentists define the probability by the its percentage of occurrence as the sample size increases to infinity, with the manipulations of random variables being convolutions; the Bayesians perceive probabilities as a belief of the next event, which updates as new data are seen. The method of combining binomial and uniform distributions fits the frequentists view, but the Bayesian view perfectly fits my requirement of a changeable initial belief.

% set up, definitions
Consider the random variable likeability $L$ of the video. Its probability density function $P(l)$ represents a belief of the likeability of the video given all data available. Before seeing any new data, this function is called the \textbf{Prior}. The arrival of new data is denoted by the symbol $D$, and the updated likeability upon seeing the new data is denoted by $P(l | D)$ --- the probability density function of the likeability \textit{given} the new data. This updated likeability is called the \textbf{Posterior}. In context with the video ratings, the prior probability will denote my initial belief on the likeabilities of the video, to which I can update my prior upon every new rating I see. The Bayesian likeability will be the statistical mean of the prior.

To find the relations between the prior and posterior probabilities, we can use the example of a medical test of a common illness.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/medical_scenario.png}
    \caption{}
    \label{fig:medical}
\end{wrapfigure}

Assuming we are faced with a patient showing no symptoms, but had taken a test of the common illness (0.1 probability of occurrence) which is positive with a sensitivity of 0.4 and a specificity of 0.9 --- meaning that there is a 40\% chance the test is positive if the patient actually has the illness, and a 90\% chance that the test is negative if the patient actually lacks the illness. Our prior beliefs before seeing the test result relies on the average chance that a random person in the area has the illness, or 10\%. The situation is shown in figure \ref{fig:medical}.

For the posterior is our beliefs after seeing the positive test result, it is calculated by the probability of the patient being ill and having a positive test result, divided against the probability the probability of a person being positive no matter their situation. This can be expressed by a formula:
\[
    \text{Posterior} = \frac{P(\text{Ill} \,\text{and}\, \text{Positive})}{P(\text{Whatever and Positive})}
\]

The notation of the probability of $A$ and $B$ is defined by the probability of $A$ times the probability of $B$ given $A$ is true. And by substituting for the symbols $P(x)$ for probability of illness, we have found Bayes Theorem:

\begin{align*}
    P(x|D) &= \frac{P(D|x) P(x)}{\sum P(D|x_i) P(x_i) }\\
     &= \frac{P(D|x)P(x)}{P(D|x)P(x) + P(D|\neg x)P(\neg x)}
\end{align*}

More specifically, the probability of illness $P(x)$ is simply the prior of illness, which is $0.1$; the probability of a positive test result given the illness $P(D|x)$ is the sensitivity of the test, or $0.4$; and the probability of a positive test result is the sum of having and not having the illness, multiplied by their respective chance of testing positive, or $0.4 \times 0.1 + (1- 0.9) \times (1-0.1)$. In our medical example, the updated belief on the probability of illness upon seeing a positive test result is therefore:
\begin{align*}
    P(x|D) &= \frac{0.4 \times 0.1}{0.4 \times 0.1 + (1-0.9) (1-0.1)}\\
    &\approx 0.308
\end{align*}
Our belief of the probability of illness of the patient had been updated from $0.01$ to $0.308$. While it is reasonable that a positive test result conveys a higher chance of illness, it still really surprised me when I first saw it. How is it that we can only be 31\% sure of the illness if the test has an accuracy of 40\%? This discrepancy with naive solutions is also present in the naive likeability method, which may be a warning that special care is needed to tread in the field of statistics --- especially if one may be diagnosing a patient wrongly.

% actual attempt
To extend this method to our likeability random variable, it will be helpful to first solve for a uniform prior as to check the validity of the solution comparing to other methods.

With the random variable likeability $L$, the initial prior $P(l)$ of the likeability is a continuous uniform distribution:
\[
    P(l) = 1
\]
Let's consider the likeability posterior $P(l|D)$ given the new data $D$ of seeing a like on the video. By Bayes Theorem, the likeability distribution after seeing a like on the video is:
\begin{align*}
    P(l|D) &= \frac{P(D|l) P(l)}{\sum P(D|l_i) P(x_i) }
\end{align*}

For we are now dealing with a functional prior and posterior (of parameter likeability), all of the probabilities in the equation will be functions and the summation must be switched to integrals. Therefore I was able to rewrite the discrete Bayes Theorem into a continuous version (the $\theta$ symbol is used as to differentiate between the function parameter and the likeability random variable ):
\[
    P(l|D)(\theta) = \frac{P(D|l)(\theta) \times P(l)(\theta)}{\int_{0}^{1} P(D|l)(\theta) \times P(l)(\theta) \, d\theta},
\]
note the integral on the denominator has bounds zero to one, inclusive, for that is the domain of the likeability random variable.

The probability of seeing a like given a specific likeability is the likeability par definition:
\[
    P(D|l)(\theta) = \theta
\]

Therefore after substitution, the equation simplifies and can be solved:
\begin{align*}
    P(l|D)(\theta) &= \frac{\theta \times 1}{\int_{0}^{1} \theta \times 1 \, d\theta}\\
    &= \frac{\theta}{\int_0^1 \theta \, d\theta}\\
    &= \frac{\theta}{[\frac{\theta^2}{2}]^1_0}\\
    &= 2\theta
\end{align*}

The posterior probability density function of the likeability of a video is $2\theta$ given a prior uniform distribution of $1$. The statistical mean $\mu$ of this function can also be calculated:
\begin{align*}
    \mu &= \int_0^1 \theta P(l|D)(\theta) \, d\theta\\
    &= \int_0^1 2\theta^2 \, d\theta\\
    &= [\frac{2\theta^3}{3}]^1_0\\
    &= \frac{2}{3}
\end{align*}

The statistical mean of a video with 1 like and no dislikes by the statistical method also agree to this value, showing the validity of the Bayesian method for the first like.
\begin{align*}
    \mu &= \frac{x+1}{n+2}\\
        &= \frac{2}{3}
\end{align*}

I thought to generalize this by seeing what happens as the prior is updated $n$ times with $n$ likes only. Consider a prior probability density function at the $n$th like of form:
\[
    P(l)(\theta) = A \theta^B,
\]
where $A$ and $B$ are constants. Our initial prior is achieved by setting $A=1$ and $B=0$.

Therefore:
\begin{align*}
    P(D|l) &= \theta\\
    P(D) &= \int_0^1 \theta A\theta^B \, d\theta\\
    P(\theta|D) &= \frac{\theta A\theta^B}{\int_0^1 \theta A\theta^B \, d\theta}\\
    &= \frac{\theta^{B+1}}{\int_0^1 \theta^{B+1} \, d\theta}\\
    &= \frac{\theta^{B+1}}{[\frac{\theta^{B+2}}{B+2}]^1_0}\\
    &= (B+2) \theta^{B+1}
\end{align*}

For the posterior is of the same form as the prior, the cycle can continue where $A_1 = B+2$ and $B_1 = B+1$, and so $B_n$ denotes the nth like received, and $A_n$ is the increment of $B_n$. The statistical mean $\mu$ of each posterior $B_n$ are:
\begin{align*}
    \mu &= \int_0^1 \theta A_n \theta^{B_n} \, d\theta\\
    &= \int_0^1 A_n \theta^{B_n + 1} \, d\theta\\
    &= A_n [\frac{\theta^{B_n+2}}{B_n+2}]^1_0\\
    &= \frac{A_n}{B_n+2}\\
    &= \frac{B_n+1}{B_n+2} = \frac{n+1}{n+2}
\end{align*}

Once again, this generalization states the bayesian likeability is the increment of the amount of likes divided by the total amount of ratings plus two. This matches the result from the statistical method, albeit with a very different perspective on probabilities and new information. I believe this updating of priors is appreciated when graphed --- figure \ref{fig:up} showcases the priors of three consecutive likes on a video.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/updating_priors.png}
    \caption{}
    \label{fig:up}
\end{figure}

To generalize the likeability solution to both likes and dislikes, consider the variable $R$ to be the event of seeing $X$ likes and $Y$ dislikes on a video. The posterior originating from a uniform prior is:
\[
    P(l|R)(\theta) = \frac{P(R|l)(\theta) P(l)(\theta)}{\int_0^1 P(R|l)(\theta) P(l)(\theta) \, d\theta}
\]

The probability of seeing $X$ likes and $Y$ dislikes given a likeability $\theta$ is determined by the binomial distribution:
\[
    P(R|l)(\theta) = {X+Y \choose X} \theta^X (1-\theta)^Y
\]

Therefore by substitution, we see a familiar form of the posterior:
\begin{align*}
    P(l|R)(\theta) &= \frac{1}{\int_0^1 {X+Y \choose X} \theta^X (1-\theta)^Y P(l)(\theta)\,d\theta}{X+Y \choose X} \theta^X (1-\theta)^Y P(l)(\theta)\\
    &= \frac{1}{\int_0^1 \theta^X (1-\theta)^Y \,d\theta} \theta^X (1-\theta)^Y
\end{align*}

By letting the variable $n=X+Y$ and $x=X$, this is the exact probability density function from the statistical method. As that method has shown using Beta and Gamma functions, the statistical mean $\mu$ of the posterior probability density function is of the form:
\begin{align*}
    \mu &= \frac{x+1}{n+2}\\
    &= \frac{X+1}{(X+1) + (Y+1)}
\end{align*}

More importantly, we can also see the Bayesian likeability of a uniform prior can be computed by the naive method of percentages, but adding one to the amount of likes and dislikes. It presents an even more handy rule to calculate the mean likeability --- use the naive method with the amount of likes plus one and the amount of dislikes plus one. The tables of video A to E are not displayed here for the values are the same as the statistical method.

Because of the Bayesian method, we are now freely able to switch out the prior probability density function. As the five videos I've sampled are from the recommendations of YouTube, and they are of a topic which I enjoy --- about mathematics, my initial prior ideally should be higher in probability with higher likeabilities, and has a statistical mean higher than 0.5, as well as fitting all attributes of a statistical distribution.

There is a function I've encountered in class when learning about inverse functions, the absolute of the square root of $x$, $|\sqrt{x}|$. The function is the positive values of the inverse function $x^2$ restricted by the domain from zero to one, inclusive, which from now would simply be referred to as the square root function. It is shown on the left graph in figure \ref{fig:sqrt_per}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/sqrt_per.png}
    \caption{}
    \label{fig:sqrt_per}
\end{figure}

The function has a positive slope throughout the domain, making it an ideal starting point of my prior distribution. However, it needs to be normalized $\text{nsqrt}(x)$ for the area it encloses is less than one (normalized shown on the right side of figure \ref{fig:sqrt_per}):
\begin{align*}
    A &= \int_0^1 \sqrt{x} \, dx\\
    &= [\frac{x^{\frac{3}{2}}}{\frac{3}{2}}]^1_0\\
    &= \frac{2}{3}
\end{align*}

\begin{align*}
     \text{nsqrt}(x) &= \frac{\sqrt{x}}{A}\\
    &= \frac{3}{2} \sqrt{x}
\end{align*}

The statistical mean $\mu$ of the normalized square root function also plays nicely, for it is above 0.5:
\begin{align*}
    \mu &= \int_0^1 x \frac{3}{2} \sqrt{x} \, dx\\
    &= \frac{3}{2} \int_0^1 x^{\frac{3}{2}} \, dx\\
    &= \frac{3}{2} [\frac{x^{\frac{5}{2}}}{\frac{5}{2}}]^1_0\\
    &= \frac{3}{5} = 0.6
\end{align*}

Using the normalized square root function as the prior, the posterior probability density function $P(l|R)$ for event $R$ of $X$ likes and $Y$ dislikes is computed by:
\begin{align*}
    P(l|R) &= \frac{1}{\int_0^1 \text{nsqrt}(\theta) \theta^X (1-\theta)^Y } \text{nsqrt}(\theta) \theta^X (1-\theta)^Y
\end{align*}

This integral is extremely difficult to compute analytically, for there is a non-constant term inside the Beta function, but I was able to simulate it and generate a numeric solution. Figure \ref{fig:up_nsqrt} is how the nsqrt prior updates for three consecutive likes on a video.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/nsqrt_updating_priors.png}
    \caption{}
    \label{fig:up_nsqrt}
\end{figure}

Therefore the Bayesian likeability of video one is numerically computed to be $\approx 0.789$. This is slightly higher than the statistical likeability of $0.778$, for I had initial high expectations expressed by the nsqrt prior probability density function.

Furthermore, it seems that not only there is no difference between treating the event seeing $X$ likes and $Y$ dislikes as one event $R$, or as multiple updates of events $D$ of one like or dislike, the order of likes and dislikes when sequentially updating also does not impact the final Bayesian likeability. This is shown in figure \ref{fig:nsqrt_incre} where the mean likeability is plotted against the nth rating for three ways of achieving the ratings of video one (6 likes and 1 dislike).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/nsqrt_incre.png}
    \caption{}
    \label{fig:nsqrt_incre}
\end{figure}

% conclude, and table
At last, the ability to plug in any prior distribution is the main advantage of the Bayesian method, as it may provide a more accurate measurement of likeability for each individual. However, it lacks the neatness of a solution provided by the statistical method, and requires a computer to compute the successive priors. Thankfully, the algorithm (appendix) scales in linear time, making it applicable as the number of likes and dislikes increase. Table \ref{tbl:baye} shows the Bayesian likeability of a nqsrt prior on the five videos.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Bayesian Likeability (nsqrt) (3dp) & 0.846 & 0.964 & 0.855 & 0.943 & 0.996
    \end{tabular}
    \captionof{table}{}
    \label{tbl:baye}
\end{figure}

\section{Conclusion}
In this exploration, I investigated a total of five different methods of finding a solution to my problem. Three of the methods have analytic solutions, while two required computers to crunch integrals or random numbers. Because of the variety of the methods, each of them have their pros and cons and usages. While the analytic solutions are the cleanest and easiest to apply with little mental effort, they require the use of algebra manipulations and calculus understandings to derive, and lack some freedom the numerical solution contains. The simulations and the Bayesian method are both computationally intensive, especially at large rating amounts, but does not require much previous knowledge and offers a lot of flexibility in choosing priors, in that order.

Ultimately, I would choose to use the Bayesian likeability with my nsqrt prior as rankings when watching the SoME1 videos. This is because it both accounts for the amount of information available on a video, and fits my prior expectations of the videos. My watching ordering will therefore be: Video E, Video B, Video D, Video C, and Video A. Nevertheless, table \ref{tbl:all} summaries the likeabilities of the five videos with all methods shown in this exploration.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
         Naive Likeability (3dp) & 1.000 & 1.000 & 0.872 & 1.000 & 0.997\\ \hline
         Simulated Likeability (3dp) & 0.828 & 0.958 &  0.853 & 0.937 & 0.987\\ \hline
         Statistical (Bayesian) Likeability (3dp) & 0.833 & 0.926 & 0.854 & 0.941 & 0.994\\ \hline
        Bayesian Likeability (nsqrt) (3dp) & 0.846 & 0.964 & 0.855 & 0.943 & 0.996
    \end{tabular}
    \captionof{table}{}
    \label{tbl:all}
\end{figure}

This project has been both entertaining to research, and also applicable in a lot of areas that I will be facing in the future for my generalizations. Whether it is finding the best book online given the ratings, or to select the most favorable bowling place given user reviews, the five methods offers me a spectrum of techniques to statistically analyze the problem. This has been a worthwhile exploration.

% bib
\nocite{*}
\printbibliography


\newpage
\section*{Appendix}


\end{document}
