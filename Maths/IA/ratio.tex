\documentclass[a4paper,11pt]{article}
\usepackage[a4paper,margin=1in,footskip=0.25in]{geometry}
\usepackage[utf8]{inputenc}

% science
\usepackage{amsmath}
\usepackage{array}
\usepackage{siunitx}

% code
% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{10} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{10}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
        language=Python,
        basicstyle=\ttm,
        morekeywords={self},              % Add keywords here
        keywordstyle=\ttb\color{deepblue},
        emph={MyClass,__init__},          % Custom highlighting
        emphstyle=\ttb\color{deepred},    % Custom highlighting style
        stringstyle=\color{deepgreen},
        frame=tb,                         % Any extra options here
        showstringspaces=false
}}


% Python environment
\lstnewenvironment{python}[1][]
{
    \pythonstyle
    \lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
        \pythonstyle
        \lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

% layout
\usepackage{float}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{circuitikz}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage[export]{adjustbox}
\usepackage{hhline}

% referencing
\usepackage[style=apa]{biblatex}
\addbibresource{ratio.bib}

% table centering
\renewcommand{\arraystretch}{1.3}
\newcolumntype{P}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcommand{\tptt}{$\times\,$}

% figures labelings
\usepackage{chngcntr}
\counterwithin{figure}{section}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}

% fancy page numbers
\usepackage{fancyhdr}
% bottom right
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[R]{Page \thepage}
\fancypagestyle{plain}{%
    \renewcommand{\headrulewidth}{0pt}%
    \fancyhf{}%
    \fancyfoot[R]{Page \thepage}%
}
%go
\renewcommand{\headrulewidth}{0pt}

\usepackage{hyperref}

\title{\vspace{-8ex}Estimating the quality of YouTube videos based on its likes and dislikes}

\author{Terry Qi}
\date{}
%\date{\vspace{-8ex}}

\begin{document}

% Planning
% Introduction
% Definition
% Steps of exploration
% Simulation Approach
% Statistical Approach
% Bayensian Approach
% Conclusion




\maketitle

\section{Introduction}

\begin{wrapfigure}{r}{0.45\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{assets/som1.png}
    \caption{The SoME1 event}
    \label{fig:some1}
\end{wrapfigure}

The topic of my exploration originates from a personal need I've developed in the school holidays.

I am familiar with the maths channel 3Blue1Brown (3B1B) on YouTube through a self learning playlist on the topic of linear algebra in year 1 IB, and was patiently waiting for a new video for it is the holidays. When Grant (owner of 3B1B) announced a contest (figure \ref{fig:some1}) not long after encouraging amateur video makers to share their hidden maths knowledges, I was understandably very excited to have my entire YouTube home page filled with the new maths videos. While I did find some brilliantly made videos like ``\href{https://www.youtube.com/watch?v=aVwxzDHniEw}{The Beauty of B\'{e}zier Curves}'' by Freya Holm\'{e}r, and an explanation of ``\href{https://www.youtube.com/watch?v=78wz4KSzUvo}{Noether's Theorem}'' by Orla M, I quickly realized my inability to view all of the thousands of videos within a two week holiday. The solution? I will only watch the best ones.

But how do you tell if a YouTube video is the ``best'' out of the bunch? Visual indicators like interesting thumbnails may be attempting, but one should really not judge the book by its cover; while comparing view counts is fast, it is against the purpose of the maths event --- to discover new talented video creators. So I am left with the only other numerical indicators, to judge the quality of the video through the amount of likes and dislikes it has. While this measure have its limitations: the internet audience is biased in political and social values, it is certainty the most interesting metric.

%(At the time of writing, the company YouTube has removed the dislike count on all videos, which is disappointing)

Therefore within this exploration, I will be finding an equation relating the amount of likes and dislikes a YouTube video has to the best estimate of its perceived quality by the viewers. I will be using multiple methods such as simulations, statistical distributions, and a Bayesian approach to deduce the relationships between the two variables. It will be crucial that I evaluate the pros and cons of each approach, both in its solution but also in its derivation, and use my knowledge to rank five videos from the SoME1 event (table \ref{tbl:videos}, appendix).
%\begin{wrapfigure}{r}{0.4\textwidth}
%    \centering
%    \includegraphics[width=0.45\textwidth]{assets/intro.png}
%    \caption{Hidden Dislikes}
%    \label{fig:hidden}
%\end{wrapfigure}

%This topic is chosen out of my curiously towards a very insignificant change. For I often procrastinate when doing my homework, I stumbled across a post on an online forum announcing the the popular internet video sharing platform of YouTube of removing their dislike counts (shown in Figure \ref{fig:hidden}). As usual, I dug into the comment section of the announcement and saw all the various complaints that one will expect on the internet, all but one has caught my eye:

%\begin{quote}
%    Dislike counts were necessary to spot clickbait, scams, fake tutorials, blatant misinformation, etc. --- Element 115 (internet user)
%\end{quote}

%The usage of likes and dislikes as a metric of legibility and quality is something that I knew and used extensively, mostly in saving my precious time in judging the qualities of the a series of maths videos made for the trend ``Summer of Math Exposition'' (SoME1) consisting of mostly amateur video makers. While the removal of the dislike counts demonstrated on how reliant I was on a simple number, it also led me to wonder of my technique in judging the quality of a video, especially in the SoME1 series for the like and dislike counts are often low. Therefore I felt this topic is worth exploring for its practicality.

% aim here

% 5 videos
% https://www.youtube.com/watch?v=-LVhZtFwZzM
% 705 2
% https://www.youtube.com/watch?v=E9IQY8LzzO8
% 35 5
% https://www.youtube.com/watch?v=vc_-aCeP7y8
% 25 0
% https://www.youtube.com/watch?v=tc53eCUvJyY
% 15 0 756
% https://www.youtube.com/watch?v=TJyCbR29Mds
% 4 0 138

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Views & 138 & 440 & 467 & 756 & 10907 \\
        \hline
        Likes & 4 & 25 & 34 & 15 & 705 \\
        \hline
        Dislikes & 0 & 0 & 5 & 0 & 2
    \end{tabular}
    \captionof{table}{}
    \label{tbl:videos}
\end{figure}


\section{Keywords}

First we have to define some keywords which are used from this point onward. All YouTube videos are referred to as videos; the \textbf{ratings} of a video are its likes and dislikes, which are both positive integers; the \textbf{likeability} is the metric used to convey the quality of a video, and is defined as a probability between 0 and 1, representing the mean probability of a viewer rating the video to select ``like''. (For example, a likeability of $0.5$ means that on average, a person rating the video is pressing the like button 50\% of the time) The focus would be to find a mathematical definition of this likeability.

To showcase an initial attempt at defining this value, consider the two following videos:

% the two videos
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/s_vid2.png}
    \caption{Video one}
    \label{fig:vid1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/s_vid1.png}
    \caption{Video two}
    \label{fig:vid2}
\end{figure}

Figure \ref{fig:vid1} is a video with 6 likes and 1 dislike. Figure \ref{fig:vid2} is a video with 23 likes and 4 dislikes. Naively, it is tempting to calculate the likeabilities ($L_n$) of the two videos by dividing the amount of likes ($x$) against the total amount of ratings ($n$). This will be called as the \textbf{naive likeability}, and is defined by:

\[
L_n = \frac{x}{n}.
\]

The naive likeabilities of video one ($L_1$) and video two ($L_2$) are thus as follow:
\begin{align*}
    L_{1} &= \frac{6}{6+1} \approx 0.857, \,\, L_{2} = \frac{23}{23 + 4} \approx 0.851.
\end{align*}

If we assume this naive mathematical definition of the likeabilities represents our language definition, then we can rate the first video higher than the second because it has a higher likeability ($0.857 > 0.851$). So we should watch video one first, right?

However, the calculations are unlikely to match our proper definitions of likeability, simply because they failed to take the total amount of ratings into consideration. While video one has a higher like to dislike ratio than video two, there are fundamentally less overall ratings available. Thus our method also needs to factor in the amount of information we can see, to include a factor of certainty, almost.

This can be illustrated with an example taken to the extreme. A video with only one like and zero dislikes have a naive likeability of 100\%, but can we really be sure that it is of a higher quality than a video with 1000 likes and 1 dislike (naive likeability of 99.9\%)?

Therefore the naive likeability definition is uninclusive of all information but is fast. Nevertheless, table \ref{tbl:naive} shows the five videos as ranked by their naive likeabilities.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Naive Likeability (3dp) & 1.000 & 1.000 & 0.872 & 1.000 & 0.997
    \end{tabular}
    \captionof{table}{}
    \label{tbl:naive}
\end{figure}


\section{Simulation}
For any statistical or probabilistic question, it is always helpful to start with a simulation of some kind. This is because a simulation allows me to both describe the problem as well as to approach a numerical solution, guaranteed by the law of large numbers --- stating that the statistical descriptions of a sample will tend towards that of the true descriptions as sample size increases.

% description of what I did
To do this, I've used Python 3.7 to write a small piece of code that does the calculations, and used a Python library called Matplotlib to graph the numbers.

Using video one (6 likes and 1 dislike) as an example, notice that it is theoretically possible for the video likeability to be of any probability except 0 and 1, for there is still a non-zero probability of receiving 6 likes on a video with 1\% likability, albeit very unlikely. Therefore I thought to define the likeability of a video by the average of all the possible likeabilities weighted by how likely they are to occur, as it matches our literal definition of ``the mean probability of a viewer rating the video to select like''.

The pseudocode for our simulation will look as follow:

\begin{python}
1   weighted = 0
2   for likeability in 0..1:
3       occurrence = simulate_occurence(likeability)
4
5       weighted += likeability * occurence / sample_size
6       plot(likeability, occurence)
\end{python}

The breakdown of this piece of code is as follows:

I first defined a variable \pythoninline{weighted} to hold the weighted average of the likeabilties:

\begin{python}
1   weighted = 0
\end{python}

Then I loop over all possible likeabilities from 0 to 1 using a \textit{for in} loop:
\begin{python}
2   for likeability in 0..1:
\end{python}

For each likability, I considered a simulation of 1000 times a group of 7 people rating the video. This is performed in the function \pythoninline{simulate_occurence}(appendix), which takes the likeability as an input. It outputs the \# of times the ratings by those 7 people matches the 6 likes and 1 dislike of video one, and saves this in the variable called \pythoninline{occurrence}.

\begin{python}
3       occurrence = simulate_occurence(likability)
\end{python}

To calculate the weighted averages (statistical mean) of the likeability, I've used the discrete mean formula, which states the mean ($\mu$) is the sum of the likeabilities ($L_i$) multiplied by their respective probabilities ($f(L_i)$):
\[
    \mu = \sum_{i = 1}^{n} L_i f(L_i)
\]

The probabilities of each possible likeability is computed in the simulate as the total occurence divided by the \pythoninline{sample_size} of 1000. This summation is reflected by adding each weighted likeability to the \pythoninline{weighted} variable for each possible likeability:

\begin{python}
5       weighted += likeability * occurence / sample_size
\end{python}

Finally I decided to plot this relationship between \pythoninline{occurence} against \pythoninline{likeability}. This is done by the \pythoninline{plot} function imported from Matplotlib:

\begin{python}
6       plot(likeability, occurence)
\end{python}

% optional
%\newpage

\begin{wrapfigure}{r}{0.47\textwidth}
    \includegraphics[width=0.44\textwidth,right]{assets/sim_ratings_v1.png}
    \caption{}
    \label{fig:sim_ratings_v1}
\end{wrapfigure}

To see the output, I ran the program with the parameters of 6 likes and 1 dislike from video one, and 1000 samples later I was greeted with the summary graph in figure \ref{fig:sim_ratings_v1}.

The blue dots in figure \ref{fig:sim_ratings_v1} represents the simulated occurence of the video ratings out of 1000 samples of a chosen likeability (the likeabilities are selected with steps of 0.05 for clarity). The red vertical line graphs the mean likeability.

The graph was both an expected and unexpected turnout. The simulation placed the likeability of video at $0.776$, this is expected for there are certainly very little information available in only 7 ratings, but unexpected in size of the difference ($0.857-0.776=0.081$) against the naive likeability of 0.857. This shows that the naive likeability greatly overvalued the true likeability of the video.

\begin{wrapfigure}{r}{0.47\textwidth}
    \includegraphics[width=0.44\textwidth,right]{assets/sim_ratings_v2.png}
    \caption{}
    \label{fig:sim_ratings_v2}
\end{wrapfigure}


By running the program with the parameters of the second video with 23 likes and 4 dislikes,
we obtain a mean of $0.828$ and figure \ref{fig:sim_ratings_v2}.

In comparison with its naive likeability, video two is less affected by the lack of information for the simulated likeability has much smaller difference ($0.851-0.828=0.023$) than we've seen in video one. This maybe imply (appendix table) that the naive likeability increases in accuracy the more information we have, which presents an extra requirement for our analytic solution later on.

The shape of the graphs, or more formally, distributions of the likeabilities are also worth noting. They very much resemble a hill shaped curve that has a peek at only one likeability, and slopes increasing shallower the further away from the peek. Interestingly, the chosen metric of the statistical mean does not reflect the peek of the curve --- the red line does not intersect at the top of the curve. I believe this has to do with the long tail of zero occurrences at lower likeabilities, for they decreases the statistical mean in calculations.

% conclusion
Therefore the simulation approach had prove to be helpful in framing the question in finding the so called statistical mean of the range of possible likeabilities, and on top of that, had created a numerical approach of estimating the likeability of videos. But it does come at a cost of accuracy and computational time, making the method unreliable and expensive to scale up to higher amounts of ratings. Table \ref{tbl:simulation} lists the five videos and their simulated likeability values with a sample size of 1000, and step 0.01.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Simulated Likeability (3dp) & 0.828 & 0.958 &  0.853 & 0.937 & 0.987
    \end{tabular}
    \captionof{table}{}
    \label{tbl:simulation}
\end{figure}

\section{Statistical}

% what are distributions
To search for a analytic (of symbols and operations) equation of the likeability metric, we must expand the idea of distributions that was touched on during simulations. Remember that the simulation was used to compute the occurrences of a given rating for all ranges of likeabilities, and the statistical mean of the curve it creates is the simulated likeability of the video. It may be helpful to define this curve more mathematically without the element of chance.

% examples of distributions
Firstly, the likeability of a video can be thought of as a \textbf{random variable} of symbol $L$. A statistical random variable represents uncertainty in a measurement of its domains --- the range of values the random variable could be.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/discrete_uniform_pdfs.png}
    \caption{}
    \label{fig:discrete_uniform}
\end{wrapfigure}

Consider rolling a regular six sided dice. The side facing up after a roll can take the values from 1 to 6, inclusive, represented by a random variable say $X$. Notice that unless the dice was biased, there is no reason to assume that one value is more probable than the other. In other words, each value of the range of possible values have equal probability of occurrence, precisely $\frac{1}{6}$. The probability can be represented as a distribution as in figure \ref{fig:discrete_uniform}.

The probability distribution of the random variable $X$ can also be denoted as a discrete uniform distribution. Discrete meaning the domain is of countable size; uniform meaning that all possible values have the same probability.

More formally, the distribution is also defined by its probability function, which is a function mapping a possible value to its chance of occurence. For our random variable $X$, its probability function $f(X_i)$ is simply:

\[
    f(X_i) = \frac{1}{6}
\]

%But our random variable of likeability does not have a finite domain, I hear you say. The random variable $L$ has infinite values it could take, ranging from zero to one. Thankfully, we can extend our discrete distribution to a continuous distribution.

To extend from a discrete distribution to a continuous distribution, consider a viewer's opinion on a video before they've seen the ratings. The likeability $L$ of the video will range continuously from zero to one, but unless the viewer has had a bad day, there is no reason to prefer a range of likeabilities to another. That is, chance of a specific likeability value is the same as any other value.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/uniform_pdfs.png}
    \caption{}
    \label{fig:uniform}
\end{wrapfigure}

However, the y-axis of probabilities must be switched to probably densities, because it is no longer accurate to talk about a specific value's probability --- we must now consider the probability of a range of values instead. The area under the probability distribution must also be of value one for normalization. Therefore, the initial probability distribution is displayed in figure \ref{fig:uniform}, with a probability density function $f(L)$ of:

\[
    f(L) = 1
\]

The concept of continuous distribution restricts the probability distribution of our likeability metric. It can be defined as a probability density function $f(L)$, with an area of one.

% the binominal
Using the ratings of video one as an example (6 likes and 1 dislike), consider a single likeability value from the domain of the random likeability variable $L$, say 0.5. What is the probability we see the ratings of video one with a true likeability of 50\%? Another distribution models this kind of scenario.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/bino_pdfs.png}
    \caption{}
    \label{fig:bino}
\end{wrapfigure}

The binomial distribution is a probability distribution that summarizes the likelihood that a value will take one of two independent values under a given success chance and assumptions (modified citation). In short, the distribution will model the distribution of the number of likes in a sample of ratings given a true likeability. It is a discrete distribution, and its discrete probability distribution function $f(x)$ is of the form:
\[
    f(x) = {n \choose x} p^x (1-p)^{n-x},
\]
where $n$ is the amount of ratings, and $p$ is the true likeability of the video. When graphed using the parameters of video one, the distribution resembles to that of figure \ref{fig:bino}.

While the distribution displays all the possible likes/dislikes combinations, the value that is of interest is colored in red. The figure describes the probability of getting 6 likes in 7 ratings as about 0.05, or 5\%. Or as a single calculation:
\[
    f(6) = {7 \choose 6} (0.5)^6 (1-0.5)^{7-6} \approx 0.05
\]
Therefore for each likeability of our random variable $L$, its probability is $f(6)$ with the variable $p$ replaced by the likeability. Therefore I was able to guess the probability density function $G(l)$ of our random variable as so (where $l$ are the range of likeabilities):
\[
    G(l) = {n \choose x} l^x (1-l)^{n-x} = {7 \choose 6} l^6 (1-l) ^{7-1}
\]
When graphed on a software, the likeability distribution looks like the left graph of figure \ref{fig:beta}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{assets/beta_pdfs.png}
    \caption{}
    \label{fig:beta}
\end{figure}

The curve plotted by $G(l)$ has a tail towards the left, with a singular peek near the value $0.85$. But the figure shows that it has an area of only $0.12$, which does not fit the requirement of a probability density function (of area one). I attempted to normalize this distribution by dividing it by its area $A$, that is:
\begin{align*}
    A &= \int_{0}^{1} G(l) \, dl\\
    &= \int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl\\
    &\approx 0.12
\end{align*}
Thus I was able to construct the normalized probability density function $K(l)$ for the likeability random variable (shown by the right graph of figure \ref{fig:beta}):
\begin{align*}
    K(l) &= \frac{G(l)}{A}\\
    &= \frac{ {n \choose x} l^x (1-l)^{n-x}} {\int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl}
\end{align*}
We are now able to take the statistical mean $\mu$ of this function, which would be the statistical solution of the estimated likeability of the video. Notice that we can restrict the integral bounds for the probability density function is only defined between 0 to 1:
\begin{align*}
    \mu &= \int_{-\infty}^{\infty} l K(l) \, dl\\
    &=\int_{0}^{1} l K(l) \, dl\\
    &=\int_{0}^{1} l \frac{ {n \choose x} l^x (1-l)^{n-x}} {\int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl} \, dl
\end{align*}
While I was able to reduce the complexity of this integral by canceling the choose function and combining the exponents, the remain integral seems unsolvable to any integration method I know:
\begin{align*}
    \mu &=\int_{0}^{1} \frac{ l^{x+1} (1-l)^{n-x}} {\int_{0}^{1} l^x (1-l)^{n-x} \, dl} \, dl\\
    &= \frac{1}{\int_{0}^{1} l^x (1-l)^{n-x} \, dl} \int_{0}^{1}  l^{x+1} (1-l)^{n-x} \, dl
\end{align*}
Thankfully, the internet was able to provide me a solution via a special function named the Beta function $B(x,y)$ and its relative the Gamma function $\Gamma(z)$(citation, wikipedia), which are defined as:
\begin{align*}
    B(x, y) &= \int_{0}^{1} l^{x-1} (1-l)^{y-1} dl\\
    \Gamma(z) &= \int_{0}^{\infty} x^{z-1} e^{-x} \, dx
\end{align*}
To put it simply, the Gamma function is a analytic continuation of the factorial operation --- meaning that it generalizes the factorial operation outside the positive integers. It has two relevant identities. The first stating its relation with the factorial operation, the second showing its identity with the Beta function.
\begin{align*}
    \Gamma(z) &= (z-1)!\\
    B(x, y) &= \frac{\Gamma(x) \Gamma(y)}{\Gamma(x + y)}
\end{align*}
I was able to simplify the formula for the statistical mean using the Beta function, which can be converted to a series of Gamma functions and therefore factorials:
\begin{align*}
    \mu &= \frac{1}{B(x+2, n-x+1)}B(x+1, n-x+1)\\
    &= \frac{\frac{\Gamma(x+2)\Gamma(n-x+1)}{\Gamma(n+3)}}{\frac{\Gamma(x+1)\Gamma(n-x+1)}{\Gamma(n+2)}} =  \frac{\frac{(x+1)!(n-x)!}{(n+2)!}}{\frac{x!(n-x)!}{(n+1)!}}\\
    &= \frac{x+1}{n+2} = \frac{6+1}{7+2} \approx 0.778
\end{align*}
It was surprising how neat the final solution was given the complexity that is the integral before. Furthermore, this shows that the statistical likeability of the video can be calculated by dividing the amount of likes plus one over the amount of ratings plus two, under the assumption that the initial likeability distribution was uniform.

The small differences between the statistical method and the simulation method ($|0.776 - 0.778| = 0.002 \approx 2.58\%$) showcases both the correctness of our solution, but it also illustrates the power of simulations --- I did not have to do any maths to get an approximate answer. Additionally, the neat solution explains the validity of the naive method at large rating numbers, for the pluses become insignificant as their operands increases.

Overall, the statistical method required a reasonable amount of statistical knowledge, and I was greatly assisted by the use of a computer program in checking the equalities between each simplifying step. However, it produced a tidy result that is easy to remember and fast to compute. Table \ref{tbl:stat} lists the five videos ranked by their statistical likeability.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Statistical Likeability (3dp) & 0.833 & 0.926 & 0.854 & 0.941 & 0.994
    \end{tabular}
    \captionof{table}{}
    \label{tbl:stat}
\end{figure}

\section{Bayesian}

The premise of this section was hinted upon within the statistical analysis of the probability distribution of the likeability random variable. While it is often reasonable to accept a perfectly uniform distribution as the initial distribution of the likeability before seeing the rating, it may not be desirable in ranking the videos YouTube recommended to me, for they are very unlikely to be of low likeability before I even see their ratings. While these external factors are difficult to capture in traditional statistical distribution analysis, it is the core idea in a branch of statistics, Bayesian statistics.

% frequenist, bayesian
The core principles in the two branches of statistics differs in their interpretations of probabilities. The frequentists define the probability by the its percentage of occurrence as the sample size increases to infinity, with the manipulations of random variables being convolutions; the Bayesians perceive probabilities as a belief of the next event, which updates as new data are seen. The method of combining binomial and uniform distributions fits the frequentists view, but the Bayesian view perfectly fits my requirement of a changeable initial belief.

% set up, definitions
Consider the random variable likeability $L$ of the video. Its probability density function $f(l)$ represents a belief of the likeability of the video given all the current data available. Before seeing any new ratings, this function is called the \textbf{Prior}.
% blah blah blah

\section{Conclusion}

% bib


\end{document}
