\documentclass[a4paper,11pt]{article}
\usepackage[a4paper,margin=1in,footskip=0.25in]{geometry}
\usepackage[utf8]{inputenc}


% science
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{array}
\usepackage{siunitx}
\usepackage{amsfonts}

% code
% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{10} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{10}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
        language=Python,
        basicstyle=\ttm,
        morekeywords={self},              % Add keywords here
        keywordstyle=\ttb\color{deepblue},
        emph={MyClass,__init__},          % Custom highlighting
        emphstyle=\ttb\color{deepred},    % Custom highlighting style
        stringstyle=\color{deepgreen},
        frame=tb,                         % Any extra options here
        showstringspaces=false
}}

\newcommand\pythonstyleln{\lstset{
        language=Python,
        basicstyle=\ttm,
        morekeywords={self},              % Add keywords here
        keywordstyle=\ttb\color{deepblue},
        emph={MyClass,__init__},          % Custom highlighting
        emphstyle=\ttb\color{deepred},    % Custom highlighting style
        stringstyle=\color{deepgreen},
        frame=tb,                         % Any extra options here
        showstringspaces=false,
        numbers=left
}}

% Python environment
\lstnewenvironment{python}[1][]
{
    \pythonstyle
    \lstset{#1}
}
{}

\lstnewenvironment{pythonln}[1][]
{
    \pythonstyleln
    \lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
        \pythonstyle
        \lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

% layout
\usepackage{float}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{hyperref}
\usepackage[export]{adjustbox}
\usepackage{hhline}
\usepackage{chngcntr}

% referencing
\usepackage[style=apa]{biblatex}
\addbibresource{ratio.bib}

% table centering
\renewcommand{\arraystretch}{1.3}
\newcolumntype{P}[1]{>{\raggedright\arraybackslash}p{#1}}
\newcommand{\tptt}{$\times\,$}

% figures labelings
\usepackage{chngcntr}
\counterwithin{figure}{section}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{wrapfig}

% fancy page numbers
\usepackage{fancyhdr}
% bottom right
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[R]{\thepage}
\fancypagestyle{plain}{%
    \renewcommand{\headrulewidth}{0pt}%
    \fancyhf{}%
    \fancyfoot[R]{\thepage}%
}
%go
\renewcommand{\headrulewidth}{0pt}
\linespread{1.25}

% custom
\DeclareMathOperator{\di}{d\!}
\newcommand*\Eval[3]{\left[#1\right]_{#3}^{#2}}

\newenvironment{Proof}[1][Proof]
{\proof[#1]\leftskip=1cm\rightskip=1cm}
{\endproof}

\usepackage{hyperref}

\title{\vspace{-8ex}Estimating the quality of YouTube videos based on its number of likes and dislikes}

\author{}
%\date{}
\date{\vspace{-8ex}}

\begin{document}

% Planning
% Introduction
% Definition
% Steps of exploration
% Simulation Approach
% Statistical Approach
% Bayensian Approach
% Conclusion



\maketitle

\section{Introduction}

\begin{wrapfigure}{r}{0.50\textwidth}
    \centering
    \includegraphics[width=0.48\textwidth]{assets/som1.png}
    \caption{The SoME1 event}
    \label{fig:some1}
\end{wrapfigure}

The topic of my exploration originates from a personal hobby I've developed in the school holidays.

Due to first year IB, I am familiar with the maths channel 3Blue1Brown (3B1B) on YouTube, for his videos are of high quality. When Grant (owner of 3B1B) announced a contest (figure \ref{fig:some1}) \parencite{sanderson} encouraging amateur video-makers to share their hidden maths knowledge, I was understandably very excited to have my entire YouTube home page filled with these new maths videos. While I did find some brilliantly made videos like ``The Beauty of B\'{e}zier Curves'' \parencite{holmer_2021}, and ``an explanation of Noether's Theorem'' \parencite{m_2021}, I quickly realized my inability to view all of the thousands of videos over a two week holiday. The solution? I will only watch the best ones.

But how do you tell if a YouTube video is the ``best'' out of the bunch? Visual indicators like interesting thumbnails are tempting, but I decided not to judge a book by its cover; while comparing view counts is fast, it is against the purpose of the maths event --- to discover new talented video creators. So I am left with the only other numerical indicators --- I want to judge the quality of the video through the number of likes and dislikes it has. While this measure can still contain subjectivity, it is certainly the most objective and interesting metric.

%(At the time of writing, the company YouTube has removed the dislike count on all videos, which is disappointing)

Therefore within this exploration, I will be finding an equation relating the number of likes and dislikes a YouTube video has to the best estimate of its perceived quality by the viewers. I will be using multiple methods such as simulations, statistical distributions, and a Bayesian approach to deduce the formula of video quality. I will evaluate the pros and cons of each approach, both in its results but also in its derivation. With the spirit of the contest, I chose to rank five random videos from the SoME1 event (table \ref{tbl:videos}).
%\begin{wrapfigure}{r}{0.4\textwidth}
%    \centering
%    \includegraphics[width=0.45\textwidth]{assets/intro.png}
%    \caption{Hidden Dislikes}
%    \label{fig:hidden}
%\end{wrapfigure}

%This topic is chosen out of my curiously towards a very insignificant change. For I often procrastinate when doing my homework, I stumbled across a post on an online forum announcing the the popular internet video sharing platform of YouTube of removing their dislike counts (shown in Figure \ref{fig:hidden}). As usual, I dug into the comment section of the announcement and saw all the various complaints that one will expect on the internet, all but one has caught my eye:

%\begin{quote}
%    Dislike counts were necessary to spot clickbait, scams, fake tutorials, blatant misinformation, etc. --- Element 115 (internet user)
%\end{quote}

%The usage of likes and dislikes as a metric of legibility and quality is something that I knew and used extensively, mostly in saving my precious time in judging the qualities of the a series of maths videos made for the trend ``Summer of Math Exposition'' (SoME1) consisting of mostly amateur video makers. While the removal of the dislike counts demonstrated on how reliant I was on a simple number, it also led me to wonder of my technique in judging the quality of a video, especially in the SoME1 series for the like and dislike counts are often low. Therefore I felt this topic is worth exploring for its practicality.

% aim here

% 5 videos
% https://www.youtube.com/watch?v=-LVhZtFwZzM
% 705 2
% https://www.youtube.com/watch?v=E9IQY8LzzO8
% 35 5
% https://www.youtube.com/watch?v=vc_-aCeP7y8
% 25 0
% https://www.youtube.com/watch?v=tc53eCUvJyY
% 15 0 756
% https://www.youtube.com/watch?v=TJyCbR29Mds
% 4 0 138

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B  & Video C  & Video D  & Video E  \\
        &  \parencite{marinov_2021} & \parencite{youtube_2021} & \parencite{aggarwal_2021} & \parencite{hoodys_2021} & \parencite{callaham_2021}\\
        \hline
        \hline
        Views & 138 & 440 & 467 & 756 & 10907 \\
        \hline
        Likes & 4 & 25 & 34 & 15 & 705 \\
        \hline
        Dislikes & 0 & 0 & 5 & 0 & 2
    \end{tabular}
    \captionof{table}{The statistics of the five videos at time of writing}
    \label{tbl:videos}
\end{figure}


\section{Ideas and Keywords}
First, we have to define some keywords that I used throughout the analysis. All YouTube videos are referred to as videos; the ratings of a video are its likes and dislikes, which are both positive integers; the likeability is the metric used to convey the quality of a video, and is represents a probability between 0 and 1, which can be defined as the mean probability of a viewer rating the video to select ``like''. (A likeability of $0.5$ means that a person rating the video is pressing the like button 50\% of the time) The focus would be to find a mathematical formula relating to this likeability.

Additionally, I am assuming that people can and will rate the video solely based on its quality --- the quality being the fundamental objective value. This eliminates rating from viewers who watched only a section of the video, or ratings given based on the creator and not the video itself. The assumption is both very idealistic and hard to confirm; notice that the five chosen videos have more views than ratings, revealing a potential bias towards the negative ratings for the satisfied viewers simply move on. This will restrict the scope of any models created in this essay, but I believe that the spirit of the contest --- to promote small creators --- will offset the usual biases, pushing these sample videos into the scope of the models.

\subsection{Naive likeability}
For my first attempt towards a formula of video likeabilities, consider video A and video C (table \ref{tbl:ex}).


\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c}
        & Video A & Video C \\
        \hline
        \hline
        Likes & 4 & 34\\
        \hline
        Dislikes & 0 & 5
    \end{tabular}
    \captionof{table}{}
    \label{tbl:ex}
\end{figure}

% the two videos
%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.7\textwidth]{assets/s_vid2.png}
%    \caption{Video one \parencite{fluency_2021}}
%    \label{fig:vid1}
%\end{figure}

%\begin{figure}[H]
%    \centering
%    \includegraphics[width=0.7\textwidth]{assets/s_vid1.png}
%    \caption{Video two \parencite{division_2021}}
%    \label{fig:vid2}
%\end{figure}

Video A has 4 likes and 0 dislike. Video C has 34 likes and 5 dislikes. I found it tempting to define the likeability by the percentage of the likes received on a video, for I imagine likeability increases as the number of likes increase, and decreases as the number of dislikes increases. I will call this method the naive likeability, defined by:
\[
    L = \frac{x}{n},
\]
where $L$ is the naive likeability, $x$ is the amount of likes, and $n$ is the amount of ratings.

The naive likeabilities of video A ($L_1$) and video C ($L_2$) can thus be computed:
\begin{align*}
    L_{1} &= \frac{4}{4} = 1, \,\, L_{2} = \frac{34}{34 + 5} \approx 0.872
\end{align*}

If we assume this naive mathematical definition of the likeabilities represents my language definition, then the first video rates higher than the second because it has a higher likeability ($1 > 0.872$). So I should watch video A first, right?

Upon reflection, the calculations are unlikely to match my language definitions of likeability. Intuitively, it is very unlikely that 100\% of people will like video A because we saw just 4 likes --- the method failed to take the total amount of ratings into consideration. While video A has a higher like to dislike ratio than video C, there are fundamentally fewer overall ratings available.

This can be illustrated with an example taken to the extreme. A video with only one like and zero dislikes have a naive likeability of 100\%, but can we really be sure that it is of a higher quality than a video with 999 likes and 1 dislike (naive likeability of 99.9\%)?

\subsection{Naive Likeability Analysis}
Therefore the naive likeability definition is noninclusive of the rating amount, but is simple to compute even in ones head. I believe that it is a naive method to rate videos when the amount of ratings are small --- I hypothesis if the naive approach will be more accurate at higher amount of ratings, as most review sites utilize such ratios objectively. Nevertheless, table \ref{tbl:naive} shows the five videos as ranked by their naive likeabilities, showing that I should watch video A,B,D first, then video E and finally video C.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Naive Likeability (3dp) & 1.000 & 1.000 & 0.872 & 1.000 & 0.997
    \end{tabular}
    \captionof{table}{}
    \label{tbl:naive}
\end{figure}

Incidentally, the low amount of ratings assisted most sampled videos to a high naive likeability. Video A, B, and D all received a perfect likeability of 100\%, while naively indicating equal quality, it feels like that video B should be of higher quality than the others due to its larger ratings count of 25. Therefore I believe that a more inclusive approach would differentiate this perfect trio, ranking video B above the others.


\section{Simulation Approach}
For any statistical or probabilistic question, I always found it helpful to start with a simulation of some kind. This is because a simulation allows me to both describe the problem as well as to generate a numerical solution, guaranteed by the law of large numbers --- stating that the statistical descriptions of a sample will tend towards that of the true descriptions as sample size increases \parencite{dekking_kraaikamp_lopuhaÃ¤_meester_2005}.

% description of what I did
To do this, I've written a small piece of code that does the calculations in Python \parencite{python37}, and also used various Python libraries to make all the graphs that are used throughout this report \parencite{matplotlib} \parencite{numpy} \parencite{scipy}.

Using video A (4 likes and 0 dislike) as an example, I thought to define the likeability of a video by the average of all the possible likeabilities weighted by how likely they are to occur, as it matches my literal definition of ``the mean probability of a viewer rating the video to select like''.

\subsection{Simulation Method}
The pseudocode for our simulation is
\begin{python}
1   weighted = 0
2   for likeability in 0..1:
3       occurrence = simulate_occurrence(likeability)
4
5       weighted += likeability * occurrence / sample_size
6       plot(likeability, occurrence)
\end{python}

I will attempt to breakdown this piece of code line by line. Firstly, I defined a variable \pythoninline{weighted} to hold the weighted average of the likeabilties:
\begin{python}
1   weighted = 0
\end{python}

Then I loop over all possible likeabilities from 0 to 1 using a \textit{for in} loop:
\begin{python}
2   for likeability in 0..1:
\end{python}

For each likability, I considered a simulation of 1000 times a group of 4 people rating the video. This is performed by the function \pythoninline{simulate_occurrence}(full source code in appendix \ref{apd:sim_occ}), which takes the likeability as an input. It outputs the number of times the ratings by those 4 people matches the 4 likes and 0 dislike of video A and saves this in the variable called \pythoninline{occurrence}.
\begin{python}
3       occurrence = simulate_occurrence(likability)
\end{python}

To calculate the weighted averages (statistical mean) of the likeability, I've used the discrete mean formula, which states the mean ($\mu$) is the sum of the likeabilities ($L_i$) multiplied by their respective probabilities ($f(L_i)$):
\[
    \mu = \sum_{i = 1}^{n} L_i f(L_i)
\]

The probabilities of each possible likeability is total occurrence divided by the \pythoninline{sample_size} of 1000. The summation is reflected by adding each weighted likeability to the \pythoninline{weighted} variable for each possible likeability:
\begin{python}
5       weighted += likeability * occurrence / sample_size
\end{python}

Finally, I decided to plot the relationship between \pythoninline{occurrence} against \pythoninline{likeability}. This is done by the \pythoninline{plot} function imported from Matplotlib:
\begin{python}
6       plot(likeability, occurrence)
\end{python}

% optional
%\newpage


To see the output, I ran the program with the parameters of 4 likes and 0 dislike from video one, and 1000 samples later I was greeted with the graph in figure \ref{fig:sim_ratings_v1}.

\begin{figure}[H]
    \centering
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{assets/sim_ratings_v1.png}
        \caption{For video A}
        \label{fig:sim_ratings_v1}
    \end{minipage}%
    \begin{minipage}{.5\textwidth}
        \centering
        \includegraphics[width=0.9\linewidth]{assets/sim_ratings_v2.png}
        \caption{For video C}
        \label{fig:sim_ratings_v2}
    \end{minipage}
\end{figure}

\subsection{Simulation Analysis}
The blue dots in figure \ref{fig:sim_ratings_v1} represents the simulated occurrence of the video ratings out of 1000 samples of a chosen likeability (the likeabilities are selected with steps of 0.01 for clarity). The red vertical line graphs the mean likeability.

The graph was both an expected and unexpected turnout. The simulation placed the likeability of video at $0.838$, this is expected for there is certainly very little information available in only 4 ratings, but unexpected in size of the difference ($1-0.838=0.162$) against the naive likeability. This confirms my suspicion that the naive likeability overvalued the true likeability of the video for.

By running the program with the parameters of the second video with 34 likes and 5 dislikes,
I've obtained a mean of $0.857$ and figure \ref{fig:sim_ratings_v2}.

In comparison with its naive likeability, video C is less affected by the lack of information for the simulated likeability has a much smaller difference ($0.872-0.857=0.015$) than that of video A's. This partially confirmed my hypothesis of the naive method gaining accuracy at larger rating counts (tested in appendix \ref{apd:acc}), and could justify the use of the naive likeability to judge popular videos.

The shape of the graphs are also worth noting.
While the two figures are very distinct in shape and symmetry, I've noticed that the peak x-value of the graphs are the naive likeabilities of the videos. This is in contrast to the statistical mean of the graphs, which leans closer to the middle and away from the peak. Statistically, this is a comparison between mode and means, and the skewness of the distributions seemed to affect the exact differences between the mode and the mean. I wonder if when the graphs are symmetrical (like a normal distribution), the naive likeability really does equate to the correct likeability.

%They very much resemble a hill shaped curve that has a peek at only one likeability, and slopes increasing shallower the further away from the peek. Interestingly, the chosen metric of the statistical mean does not reflect the peek of the curve --- the red line does not intersect at the top of the curve. I believe this has to do with the long tail of zero occurrences at lower likeabilities, for they decrease the statistical mean in calculations.

% conclusion
Nevertheless, the simulation approach had proved to be helpful in framing the question in finding the so-called statistical mean of the range of possible likeabilities. On top of that, it had created a numerical method of estimating the likeability of videos. But it does come at a cost of precision and computational time, making the method unreliable and expensive to scale up to higher amounts of ratings. Table \ref{tbl:simulation} lists the five videos and their simulated likeability values with a sample size of 1000, and step 0.01.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Simulated Likeability (3dp) & 0.828 & 0.958 &  0.853 & 0.937 & 0.987
    \end{tabular}
    \captionof{table}{}
    \label{tbl:simulation}
\end{figure}

Two things are to be highlighted here. Firstly notice the slight variations in the simulated likeability values of video A,C, which I believe is caused by the random number generators. While larger sample sizes could reduce the variations at the cost of computational time, such errors may reduce the validity of the results during comparisons. Secondly notice that this metric of likeability had video C exceed video A, opposite of the conclusions made in the naive likeability section. It also confirmed my hypothesis that video B will score higher than video A,D --- this likeability measurement seems to be what I am looking for.

\section{Statistical Approach}

% what are distributions
To formalize and reduce the variations of the simulation approach, I sought for a analytic equation of the likeability metric. Remember that the simulation was used to compute the occurrences of a given rating for all ranges of likeabilities, and the statistical mean of the curve it creates is the simulated likeability of the video. It may be helpful to define this curve more mathematically without the element of chance in the occurrence function.

% examples of distributions
\subsection{Continuous Random Variables and Prior Distribution}
Firstly, the likeability of a video can be thought of as a continuous random variable of symbol $L$ of domain $[0, 1]$, as the likeability can range from 0\% to 100\%.
%\begin{wrapfigure}{r}{0.45\textwidth}
 %   \includegraphics[width=0.43\textwidth,right]{assets/discrete_uniform_pdfs.png}
%    \caption{}
%   \label{fig:discrete_uniform}
%\end{wrapfigure}

%Consider rolling a regular six-sided dice. The side facing up after a roll can take the values from 1 to 6, inclusive, represented by a random variable say $X$. Notice that unless the dice was biased, there is no reason to assume that one value is more probable than the other. In other words, each value of the range of possible values has equal probability of occurrence, precisely $\frac{1}{6}$. The probability can be represented as a distribution as in figure \ref{fig:discrete_uniform}.

%The probability distribution of the random variable $X$ can also be denoted as a discrete uniform distribution. Discrete means the domain is of countable size; uniform means that all possible values have the same probability.

%More formally, the distribution is also defined by its probability function, which is a function mapping a possible value to its chance of occurrence. For our random variable $X$, its probability function $f(X_i)$ is simply:

%\[
%    f(X_i) = \frac{1}{6}
%\]

%But our random variable of likeability does not have a finite domain, I hear you say. The random variable $L$ has infinite values it could take, ranging from zero to one. Thankfully, we can extend our discrete distribution to a continuous distribution.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/uniform_pdfs.png}
    \caption{}
    \label{fig:uniform}
\end{wrapfigure}

Without any assumptions, the probability density function of a viewer's opinion on a video before they've seen the ratings is a uniform distribution (figure \ref{fig:uniform}). Before seeing the ratings, the likeability $L$ of the video will range continuously from zero to one, but unless the viewer has had a bad day, there is no reason to prefer a range of likeabilities to another. That is, the probability density of a specific likeability value is uniform:
\[
    L \sim U(0, 1).
\]

%However, the y-axis of probabilities must be switched to probably densities, because it is no longer accurate to talk about a specific value's probability --- we must now consider the probability of a range of values instead

Additionally, the area under the probability distribution must be of unit 1. Therefore, the initial probability distribution displayed in figure \ref{fig:uniform} has a probability density function $f(L)$ of:
\[
    f(L) = 1.
\]

Moreover, the statistical mean of this distribution should be initial thought of this unwatched and unrated video. I expect this to be 50\% as there is no reason for me to assume its quality initially --- this is a point that is debated later. Mathematically, the mean $\mu$ of this distribution is:
\begin{align*}
    \mu &= \int_0^1 x \, dx\\
    &= \Eval{\frac{x^2}{2}}{1}{0}\\
    &= 0.5,
\end{align*}
which fulfills this expectations.
%The requirements of continuous distributions restrict the probability distribution of our likeability metric --- it must be positive for all x values in the x-axis domain and have an area of one.

The uniform distribution of a viewer's prior belief of the likeabilities of a video is an indication of a lack of weightings to the statistical mean calculations of the final step.

% the binominal
\subsection{Specific and General Likeability Distributions}
Building on the simulation approach, I am looking for an analytic equation to the \verb|simulate_occurence| function performed at each likeability value.

Consider a single likeability value from the domain of the random variable $L$, say $l=0.5$. What is the probability that we see the exact ratings of video A if it had a true likability of 50\%? I remembered the binomial distribution.

\begin{wrapfigure}{r}{0.45\textwidth}
    \includegraphics[width=0.43\textwidth,right]{assets/bino_pdfs.png}
    \caption{For Video A}
    \label{fig:bino}
\end{wrapfigure}

The binomial distribution is a probability distribution that determines the number of successes in n trials under a given success chance \parencite{barone_2021}. In short, the distribution can model the probability of seeing x likes in n ratings given a likeability. Its probability distribution function $f(x)$ is of the form:
\[
    f(x) = {n \choose x} l^x (1-l)^{n-x},
\]
where $n$ is the number of ratings, $x$ is the number of likes seen, and $l$ is the assumed likeability of the video. When graphed using the ratings of video A, the distribution resembles that of figure \ref{fig:bino}.

While the distribution displays all the possible likes/dislikes combinations, the value that is of interest is colored in red. The figure shows that the probability of getting 4 likes in 4 ratings is about 0.06 or 6\% if the underlying likeability is 50\% --- very unlikely. Or as a single calculation:
\[
    f(4) = {4 \choose 4} (0.5)^4 (1-0.5)^{4-4} \approx 0.06.
\]

Therefore for each likeability of our random variable $L$, its occurrence function is $f(4)$ with the specific likeability. Thus I believe the probability density function $G(l)$ of the random variable is a binomial distribution with parameters $l$ rather than $x$, and is written as:
\begin{align*}
    G(l) &= {n \choose x} l^x (1-l)^{n-x} = {4 \choose 4} l^4 (1-l) ^{4-4}\\
    &= l^4
\end{align*}

When graphed in software, the likeability distribution looks like the left graph of figure \ref{fig:beta}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{assets/beta_pdfs.png}
    \caption{For Video A}
    \label{fig:beta}
\end{figure}

Notice that the left figure perfectly matches the simulated distribution with a left skew and a peak near $0.83$, albeit smoother and continuous.

\subsection{Likeability Distribution Normalization}
But the figure shows that it has an area of only $\approx 0.20$, which does not fit the requirement of a probability density function of unit area. I attempted to normalize this distribution by dividing it by its area $A$, more accurately:
\begin{align*}
    A &= \int_{0}^{1} G(l) \, dl\\
    &= \int_{0}^{1} l^4 \, dl\\
    &= \Eval{\frac{l^5}{5}}{1}{0}\\
    &= 0.2,
\end{align*}

and the normalized distribution $K(l)$ is (shown by the right graph of figure \ref{fig:beta}):
\begin{align*}
    K(l) &= \frac{G(l)}{A}\\
    &= \frac{l^4}{0.2}\\
    &= 5l^4
\end{align*}

To generalize, the normalized distribution of a video with any amount of ratings is:
\begin{align*}
    K(l) &= \frac{G(l)}{A}\\
     &= \frac{ {n \choose x} l^x (1-l)^{n-x}} {\int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl},
\end{align*}
where $n$ is the amount of ratings, and $x$ is the number of likes.

\subsection{Statistical Mean of Likeability Distribution}
I can now precisely compute the statistical mean $\mu$ of this distribution, which directly reflects the simulation approach and is likely to be the likeability metric I am looking for. Notice the uniform weighting of the statistical mean justified by the uniform prior distribution, and that the integral bounds for the probability density function is restricted between 0 to 1 as $K(l)$ is precisely $0$ outside the domain:
\begin{align*}
    \mu &= \int_{0}^{1} l K(l) \, dl\\
    &= \int_{0}^{1} 5l^5 \, dl\\
    &= \Eval{\frac{5}{6} l^6}{1}{0}\\
    &= \frac{5}{6} \approx 0.83,
\end{align*}
thus agreeing with the result of the simulation approach on video A.

Generally, the statistical mean for a video with $n$ amount of ratings and $x$ likes is:
\begin{align*}
    \mu &=\int_{0}^{1} l K(l) \, dl\\
    &=\int_{0}^{1} l \frac{ {n \choose x} l^x (1-l)^{n-x}} {\int_{0}^{1} {n \choose x} l^x (1-l)^{n-x} \, dl} \, dl.
\end{align*}

While I was able to reduce the complexity of this integral by canceling the choose function and combining the exponents, the remain integral seems unsolvable to any integration method I know:
\begin{align*}
    \mu &= \int_{0}^{1} \frac{ l^{x+1} (1-l)^{n-x}} {\int_{0}^{1} l^x (1-l)^{n-x} \, dl} \, dl\\
    &= \frac{1}{\int_{0}^{1} l^x (1-l)^{n-x} \, dl} \int_{0}^{1}  l^{x+1} (1-l)^{n-x} \, dl.
\end{align*}

Thankfully, the internet was able to provide me a solution via a special function named the Beta function $B(x,y)$ \parencite{wikipedia_2021} and its relative the Gamma function $\Gamma(z)$ \parencite{artin_2006}, which are defined as:
\begin{align}
    B(a, b) &= \int_{0}^{1} l^{a-1} (1-l)^{b-1} dl\label{eq:beta}\\
    \Gamma(z) &= \int_{0}^{\infty} x^{z-1} e^{-x} \, dx.\label{eq:gammma}
\end{align}

There are two relevant identities for the Gamma function. The first states its relation with the factorial operation when its arguments are integers, the second showing its identity with the Beta function:
\begin{align}
    \Gamma(z) &= (z-1)! \label{eq:gammaident}\\
    B(a, b) &= \frac{\Gamma(a) \Gamma(b)}{\Gamma(a + b)} \label{eq:betaident}.
\end{align}

I was able to simplify the formula for the statistical mean using the Beta function, which can be converted to a series of Gamma functions and therefore into factorials.

Through identity Eq. \ref{eq:beta}, notice that:
\begin{align*}
    \int_{0}^{1} l^x (1-l)^{n-x} \, dl &= B(x+1, n-x+1)\\
    \int_{0}^{1}  l^{x+1} (1-l)^{n-x} \, dl &= B(x+2, n-x+1),
\end{align*}

therefore
\begin{align*}
    \mu &= \frac{1}{B(x+1, n-x+1)}B(x+2, n-x+1)\\
    &= \frac{\frac{\Gamma(x+2)\Gamma(n-x+1)}{\Gamma(n+3)}}{\frac{\Gamma(x+1)\Gamma(n-x+1)}{\Gamma(n+2)}} \tag*{using Eq. \ref{eq:betaident}}\\
    &=  \frac{\frac{(x+1)!(n-x)!}{(n+2)!}}{\frac{x!(n-x)!}{(n+1)!}}  \tag*{using Eq. \ref{eq:gammaident}}\\
    &= \frac{x+1}{n+2}
\end{align*}

I was surprised by how neat the final solution turned out, contrasting the messy integrals beforehand. Nevertheless, this shows that the statistical likeability of any video can be calculated by dividing the number of likes plus one over the number of ratings plus two.

\subsection{Method Analysis}
The statistical approach is in agreement with the simulation approach, in that it ranks the likeability of video C ($\frac{34+1}{34+6+2} \approx 0.854$) higher than that of video A ($\frac{5}{6} \approx 0.833$). The contrast is the lack of variance in this analytic solution. If this metric of likeability is really representative, the high accuracy of the statistical solution and simple calculations helps to make the approach to be viable in large scales in real world review sites, where small ratings are frequent and computational time is costly.

%The small difference between the statistical method and the simulation method ($|0.776 - 0.778| = 0.002 \approx 2.58\%$) showcases not only the correctness of this solution, but it also illustrates the power of simulations --- I did not have to do any maths to get an approximate answer. However, this neat solution explains the validity of the naive method at large rating numbers, for the plus ones and twos become insignificant as their operands increases.

Overall, the statistical method required a reasonable amount of statistical knowledge, and I was greatly assisted by the use of a computer program in checking the equalities between each simplifying step. Nevertheless, it produced a tidy result that is easy to remember and fast to compute --- the number of likes plus one over the number of ratings plus two. Table \ref{tbl:stat} lists the five videos ranked by their statistical likeability. Notice that the numbers and the trends of likeability closely resembles that of the simulated likeabilities.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Statistical Likeability (3dp) & 0.833 & 0.962 & 0.854 & 0.941 & 0.996
    \end{tabular}
    \captionof{table}{}
    \label{tbl:stat}
\end{figure}

Upon inspection, I've noticed that when compared with the naive method, their differences decrease when the number of ratings increase --- notice that video B's difference ($1-0.962 = 0.038$) is much smaller than video A's difference ($1-0.833= 0.167$). Mathematically, the plus one and plus two has diminishing effects on the likeability of a video as the numerator and denominator increases, which confirms my hypothesis that the naive method approaches the representative likeability at larger ratings.

While this inspection could justify the use of likes to ratings ratios as metrics for judgment of quality for popular videos, I believe the minimal additional computation required for the statistical measurement does not justify such approximations on review sites --- especially for arguments of the largeness of ratings needed for a close approximation. Is 1000 ratings enough? What about 2000? I believe that the statistical approach that is simple and representative should always be used for consistency and correctness.

\section{Bayesian Approach}
The premise of this section was hinted upon within the statistical analysis of the probability distribution of the likeability random variable. I am going to break the premise of the prior uniform probability density function. The myriads of reasons include: YouTube recommendations are algorithmic and is unlikely to recommend me a low likeability video; it is very difficult to make a poor maths video on a topic, for I believe the subject has a high skill ceiling of entering; and personally, I enjoy watching these maths videos online, and have slightly higher expectations of the community. While these factors are difficult to capture in traditional statistical distribution analysis, it is the core idea in a branch of statistics called Bayesian statistics.

% frequenist, bayesian
The core principles in the two branches of statistics differ in their interpretations of probabilities. The frequentists define the probability by its percentage of occurrence as the sample size increases to infinity, with the manipulations of random variables being convolutions; the Bayesians perceive probabilities as a belief of the next event, which updates as new data are seen. The method of combining binomial and uniform distributions fits the frequentists view, but the Bayesian view perfectly fits my requirement of a changeable initial belief.

% set up, definitions
\subsection{Defining the Bayesian Prior, Posterior, and Event}
Consider the random variable likeability $L$ of the video. Its probability density function $P(l)$ represents a belief in the likeability of the video given all data available. Before seeing any new data, this function is called the Prior. The arrival of new data is denoted by the symbol $D$, and the updated likeability upon seeing the new data is denoted by $P(l | D)$ --- the probability density function of the likeability \textit{given} the new data. This updated likeability is called the Posterior. In the context of video ratings, the prior probability will denote my initial belief on the likeabilities of the video, to which I can update my prior upon every new rating I see. I believe that I can define the Bayesian likeability to be the statistical mean of the belief function after seeings the ratings of the videos.

%To find the relations between the prior and posterior probabilities, we can use the example of a medical test of a common illness.

%\begin{wrapfigure}{r}{0.45\textwidth}
%    \includegraphics[width=0.43\textwidth,right]{assets/medical_scenario.png}
 %   \caption{}
 %   \label{fig:medical}
%\end{wrapfigure}

%Assuming we are faced with a patient showing no symptoms, but had taken a test of the common illness (0.1 probability of occurrence) which is positive with a sensitivity of 0.4 and a specificity of 0.9 --- meaning that there is a 40\% chance the test is positive if the patient actually has the illness; and a 90\% chance that the test is negative if the patient actually lacks the illness. Our prior beliefs before seeing the test result rely on the average chance that a random person in the area has the illness, or 10\%. The situation is shown in figure \ref{fig:medical}.

%For the posterior is our beliefs after seeing the positive test result, it is calculated by the probability of the patient being ill and having a positive test result, divided against the probability of a person being positive no matter their situation. This can be expressed by a formula:
%\[
  %  \text{Posterior} = \frac{P(\text{Ill} \,\text{and}\, \text{Positive})}{P(\text{Whatever and Positive})}
%\]

%The notation of the probability of $A$ and $B$ is defined by the probability of $A$ times the probability of $B$ given $A$ is true. And by substituting for the symbols $P(x)$ for the probability of illness, we have found Bayes Theorem:
The regular Bayes theorem for updating discrete probabilities should be familiar:
\begin{align*}
    P(x|D) &= \frac{P(D|x) P(x)}{\sum P(D|x_i) P(x_i) }
\end{align*}
where $x$ is the prior belief of some event, and $x_i$ representing the space of all possible events.

%More specifically, the probability of illness $P(x)$ is simply the prior of illness, which is $0.1$; the probability of a positive test result given the illness $P(D|x)$ is the sensitivity of the test, or $0.4$; and the probability of a positive test result is the sum of having and not having the illness, multiplied by their respective chance of testing positive, or $0.4 \times 0.1 + (1- 0.9) \times (1-0.1)$. In our medical example, the updated belief on the probability of illness upon seeing a positive test result is thus:
%\begin{align*}
%    P(x|D) &= \frac{0.4 \times 0.1}{0.4 \times 0.1 + (1-0.9) (1-0.1)}\\
%    &\approx 0.308
%\end{align*}
%Our belief of the probability of illness of the patient had been updated from $0.01$ to $0.308$. While it is reasonable that a positive test result conveys a higher chance of illness, it still really surprised me when I first saw it. How is it that we can only be 31\% sure of the illness if the test has an accuracy of 40\%? This discrepancy with naive solutions is also present in the naive likeability method, which may be a warning that special care is needed to tread in the field of statistics --- especially if one may be diagnosing a patient wrongly.

% actual attempt
I would need to extend this theorem to fit the continuous belief of the likeabilities of a video. To check for the validity of this method, I will be first applying the extended method on an uniform prior.

\subsection{Prior Updating and the Continous Bayes Theorem}
With the random variable likeability $L$, the initial prior $P(l)$ of the likeability is a continuous uniform distribution:
\[
    P(l) = 1.
\]

Let's consider the likeability posterior $P(l|D)$ given the new data $D$ of seeing a like on the video. By Bayes Theorem, the likeability distribution after seeing a like on the video is:
\begin{align*}
    P(l|D) &= \frac{P(D|l) P(l)}{\sum P(D|l_i) P(x_i) }.
\end{align*}

Because we are now dealing with a functional prior and posterior (of parameter likeability), all of the probabilities in the equation will be functions and the summation must be switched to integrals. Therefore I was able to rewrite the discrete Bayes Theorem into a continuous version (the $\theta$ symbol is used to differentiate between the function parameter and the likeability random variable ):
\[
    P(l|D)(\theta) = \frac{P(D|l)(\theta) \times P(l)(\theta)}{\int_{0}^{1} P(D|l)(\theta) \times P(l)(\theta) \, d\theta},
\]
note the integral on the denominator has bounds zero to one, inclusive, for that is the domain of the prior likeability random variable.

The probability of seeing one like given a specific likeability is the likeability from definition:
\[
    P(D|l)(\theta) = \theta.
\]

Therefore after substitution, the equation simplifies and can be solved:
\begin{align*}
    P(l|D)(\theta) &= \frac{\theta \times 1}{\int_{0}^{1} \theta \times 1 \, d\theta}\\
    &= \frac{\theta}{\int_0^1 \theta \, d\theta}\\
    &= \frac{\theta}{\Eval{\frac{\theta^2}{2}}{1}{0}}\\
    &= 2\theta.
\end{align*}

\newpage
The posterior probability density function of the likeability of a video is $2\theta$ given a prior uniform distribution of $1$. The statistical mean $\mu$ of this function can also be calculated to be around $66.7\%$.
\begin{align*}
    \mu &= \int_0^1 \theta P(l|D)(\theta) \, d\theta\\
    &= \int_0^1 2\theta^2 \, d\theta\\
    &= \Eval{\frac{2\theta^3}{3}}{1}{0}\\
    &= \frac{2}{3}.
\end{align*}

The statistical mean of a video with 1 like and no dislikes by the statistical method also agree with this value, showing the agreement of the Bayesian method for the first like.
\begin{align*}
    \mu &= \frac{x+1}{n+2}\\
        &= \frac{2}{3}
\end{align*}

\subsection{N-Likes Generalization}
I thought to generalize this by seeing what happens as the prior is updated $n$ times with $n$ likes only. Consider a belief probability density function at the $n$th like of the form:
\[
    P(l)_n(\theta) = A_n \theta^{B_n},
\]
where $A_n$ and $B_n$ are constants. Our initial prior is achieved by setting $A_0=1$ and $B_0=0$. The example of 1 like shows that $A_1 = 2$ and $B_1 = 1$, thus I hypothesize that $A_n = n+1$ and $B_n = n$. I proved this statement below.

\begin{Proof}
	I will prove the N-Likes Generalization statement for $n\in \mathbb{N}$ through mathematical induction.

	The case when $n=1$ is already proven through the example.

	Now assume that the case holds when $n=k$, $k > 1$. Therefore $A_k = k+1$ and $B_k = k$.

	The prior probability density at $k$ likes is thus:
	\[
	P(l)(\theta) = (k+1) \theta ^{k}
	\]

	The probability of the next like is still $\theta$:
	\begin{align*}
	P(D|l) &= \theta
	\end{align*}

	and the posterior is computed via the continuous Bayes theorem:
	\begin{align*}
	P(\theta|D) &= \frac{P(D|l)(\theta) \times P(l)(\theta)}{\int_{0}^{1} P(D|l)(\theta) \times P(l)(\theta) \, d\theta}\\
	&= \frac{\theta (k+1)\theta^k}{\theta \int_0^1 (k+1)\theta^k \, d\theta}\\
	&= \frac{\theta^{k+1}}{\int_0^1 \theta^{k+1} \, d\theta}\\
	&= \frac{\theta^{k+1}}{\Eval{\frac{\theta^{k+2}}{k+2}}{1}{0}}\\
	&= (k+2) \theta^{k+1}.
	\end{align*}

	Because the posterior is the belief function of $k+1$ likes, the following holds:
	\begin{align*}
	A_{k+1} \theta^{B_{k+1}} &= (k+2) \theta ^{k+1}\\
	A_{k+1} &= k+2\\
	&= (k+1) + 1\\
	B_{k+1} &= k+1\\
	&= (k+1),
	\end{align*}
	hence proving that the case holds for $n=k+1$ as well.

	Therefore by the principle of mathematical induction, because the case holds for $n=1$, and if $n=k$ is held, $n=k+1$ will be held, the case will hold for all $n\in\mathbb{N}$.
\end{Proof}




%Because the posterior is of the same form as the prior, the cycle can continue where $A_{n+1} = B_{n}+2$ and $B_{n+1} = B_n+1$, and so $B_n$ denotes the nth like received, and $A_n$ is one above $B_n$.


Therefore the statistical mean $\mu_n$ for the $n$th like's posterior function is:
\begin{align*}
    \mu_n &= \int_0^1 \theta A_n \theta^{B_n} \, d\theta\\
    &= \int_0^1 A_n \theta^{B_n + 1} \, d\theta\\
    &= A_n \Eval{\frac{\theta^{B_n+2}}{B_n+2}}{1}{0}\\
    &= \frac{A_n}{B_n+2}\\
    &= \frac{B_n+1}{B_n+2} = \frac{n+1}{n+2}.
\end{align*}

Once again, this generalization states the Bayesian likeability is the increment of the number of likes divided by the total amount of ratings plus two. This matches the result from the statistical method, albeit with a very different perspective on probabilities and new information. I believe this updating of priors is more appreciated when graphed --- figure \ref{fig:up} showcases the priors of three consecutive likes on a video. Notice how the most likes seen, the less likely the lower likeability values are to occur and the more likely the higher likeability values are to occur.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/updating_priors.png}
    \caption{}
    \label{fig:up}
\end{figure}

\subsection{X-Likes Y-Dislikes Generalization}
To generalize the likeability solution to both likes and dislikes, consider the variable $R$ to be the event of seeing $X$ likes and $Y$ dislikes on a video. The posterior originating from a uniform prior is:
\[
    P(l|R)(\theta) = \frac{P(R|l)(\theta) P(l)(\theta)}{\int_0^1 P(R|l)(\theta) P(l)(\theta) \, d\theta}.
\]

The probability of seeing $X$ likes and $Y$ dislikes given a likeability $\theta$ is determined by the binomial distribution:
\[
    P(R|l)(\theta) = {X+Y \choose X} \theta^X (1-\theta)^Y.
\]

When canceling the choose functions in the numerator and denominator, I saw a familiar form of the posterior:
\begin{align*}
    P(l|R)(\theta) &= \frac{1}{\int_0^1 {X+Y \choose X} \theta^X (1-\theta)^Y P(l)(\theta)\,d\theta}{X+Y \choose X} \theta^X (1-\theta)^Y P(l)(\theta)\\
    &= \frac{1}{\int_0^1 \theta^X (1-\theta)^Y \,d\theta} \theta^X (1-\theta)^Y.
\end{align*}

By letting the variable $n=X+Y$ and $x=X$, this is the exact probability density function from the statistical method $K(l)$. As that method has shown using Beta and Gamma functions, the statistical mean $\mu$ of the posterior probability density function is of the form:
\begin{align*}
    \mu &= \frac{x+1}{n+2}\\
    &= \frac{X+1}{(X+1) + (Y+1)}.
\end{align*}

More importantly, we can also see the Bayesian likeability of a uniform prior can be computed similarly to the naive method of percentages, but adding one to the number of likes and dislikes. It presents an even more handy rule to calculate the mean likeability --- use the naive method with the number of likes plus one and the number of dislikes plus one. This had confirmed my hypothesis earlier in that videos with symmetrical ratings have unchanged naive and simulation likeabilities, for the ratio between $a$ likes against $b$ dislikes is the same as the ratio between $a+1$ likes and $b+1$ dislikes. I wonder also if naive likeabilities also becomes more accurate when the likeability approaches near 50\% where the skewness is lower.

The tables of videos A to E are not displayed here for the values are the same as the statistical method.

\subsection{Personal Square-root Prior}
Because of the Bayesian method, I can now freely switch out the prior probability density function. As the five videos I've sampled are from the recommendations of YouTube, and they are of a topic which I enjoy --- about mathematics, my initial prior ideally should be higher in probability with higher likeabilities, and has a statistical mean higher than 0.5, as well as fitting all attributes of a statistical distribution.

There is a function I've encountered in class when learning about inverse functions, the absolute of the square root of $x$, $y=|\sqrt{x}|$. The function contains the positive values of $x^2$'s inverse function. I will restrict it from $0$ to $1$ and call it the square root function. It is shown on the left graph in figure \ref{fig:sqrt_per}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{assets/sqrt_per.png}
    \caption{}
    \label{fig:sqrt_per}
\end{figure}

The function has a decreasing positive slope throughout the domain, meaning that while higher likeabilities are more probable, the rate at which this increases is decreasing so that I am not heavily favoring these videos exponentially. However, it needs to be normalized to $\text{nsqrt}(x)$ for the area it encloses is less than one.

We can simply scale the function down by the area $A$ it encloses:
\begin{align*}
    A &= \int_0^1 \sqrt{x} \, dx\\
    &= \Eval{\frac{x^{\frac{3}{2}}}{\frac{3}{2}}}{1}{0}\\
    &= \frac{2}{3}.
\end{align*}

Therefore I've defined the normalized square-root function to be:
\begin{align*}
     \text{nsqrt}(x) &= \frac{\sqrt{x}}{A}\\
    &= \frac{3}{2} \sqrt{x}.
\end{align*}

The statistical mean $\mu$ of the normalized square root function also satisfies my prior, for it is above 0.5, corresponding to my initial high expectations of these videos.
\begin{align*}
    \mu &= \int_0^1 x \frac{3}{2} \sqrt{x} \, dx\\
    &= \frac{3}{2} \int_0^1 x^{\frac{3}{2}} \, dx\\
    &= \frac{3}{2} \Eval{\frac{x^{\frac{5}{2}}}{\frac{5}{2}}}{1}{0}\\
    &= \frac{3}{5} = 0.6.
\end{align*}

Using the normalized square root function as the prior, the posterior probability density function $P(l|R)$ for event $R$ of $X$ likes and $Y$ dislikes is computed by:
\begin{align*}
    P(l|R) &= \frac{1}{\int_0^1 \text{nsqrt}(\theta) \theta^X (1-\theta)^Y } \text{nsqrt}(\theta) \theta^X (1-\theta)^Y.
\end{align*}

This integral is extremely difficult to compute analytically, for there is a non-constant term inside the Beta function, but I was able to integrate it using software and generate a numerical solution. Figure \ref{fig:up_nsqrt} shows how the nsqrt prior updates for three consecutive likes on a video.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/nsqrt_updating_priors.png}
    \caption{}
    \label{fig:up_nsqrt}
\end{figure}

%Therefore the Bayesian likeability of video one is numerically computed to be $\approx 0.789$. This is slightly higher than the statistical likeability of $0.778$, reflecting how I had initial high expectations expressed by the nsqrt prior probability density function.

Furthermore, I found that not only is there no difference between treating the event seeing $X$ likes and $Y$ dislikes as one event $R$, or as multiple updates of events $D$ of one like or dislike, the order of likes and dislikes when sequentially updating also does not impact the final Bayesian likeability. This is shown in figure \ref{fig:nsqrt_incre} where the mean likeability is plotted against the nth rating for three ways of achieving the ratings of a video with 6 likes and 1 dislike.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{assets/nsqrt_incre.png}
    \caption{}
    \label{fig:nsqrt_incre}
\end{figure}

% conclude, and table
\subsection{Method Analysis}
At last, the ability to substitute in any prior distribution is the main advantage of the Bayesian method. This will provide a more accurate measurement of likeability for each individual video on a personal basis, which could increase the satisfaction of viewers and save me time. Furthermore, it provides an accurate metric for comparing between video genres, for I may have different priors and expectations for different types of videos --- I am likely to have a lower expectation to cooking videos, and will use a decreasing prior of $y=e^{-x}$. However, it lacks the swiftness of a solution provided by the statistical method and requires a computer to compute the successive priors. Painfully, my algorithm scales in exponential time, making it less applicable as the number of likes and dislikes increase (appendix \ref{apd:algo}). Table \ref{tbl:baye} shows the Bayesian likeability of a nqsrt prior on the five videos.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
        Bayesian Likeability (nsqrt) (3dp) & 0.846 & 0.964 & 0.855 & 0.943 & 0.996
    \end{tabular}
    \captionof{table}{}
    \label{tbl:baye}
\end{figure}

I've noticed that while the order of viewing is unchanged from the case of uniform priors, the likeability values did shift for a majority of the videos. Video A is rated slightly higher than before (from $0.833$ to $0.846$), placing it closer to video C. I believe that this indicates the additional trust I've given to videos with less ratings, and could be more significant with more samples.

\section{Conclusion}
In this exploration, I investigated a total of five different methods of finding a solution to my problem. Three of the methods have analytic solutions, while two required computers to crunch integrals and random numbers. Due of the variety of the methods, each of them has their pros and cons and usages. While the analytic solutions are the cleanest and easiest to apply with little mental effort, they require the use of algebra manipulations and calculus understandings to derive, and lack the freedom the numerical solution contains. The simulations and the Bayesian method are both computationally intensive, especially at large rating amounts, but does not require much previous knowledge and offers a lot of flexibility in choosing priors, in that order.

Ultimately, I would choose to use the Bayesian likeability with my nsqrt prior as rankings when watching the SoME1 videos. This is because it both accounts for the amount of information available on a video, and fits my prior expectations of the videos --- its downside of extra computing time is minimal as the rating counts are small. My watching ordering will therefore be: Video E, Video B, Video D, Video C, and Video A. Nevertheless, table \ref{tbl:all}  summaries the likeabilities of the five videos with all methods shown in this exploration.

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & Video A & Video B & Video C & Video D & Video E \\
        \hline
        \hline
         Naive Likeability (3dp) & 1.000 & 1.000 & 0.872 & 1.000 & 0.997\\ \hline
         Simulated Likeability (3dp) & 0.828 & 0.958 &  0.853 & 0.937 & 0.987\\ \hline
         Statistical (Bayesian) Likeability (3dp) & 0.833 & 0.962 & 0.854 & 0.941 & 0.996\\ \hline
        Bayesian Likeability (nsqrt) (3dp) & 0.846 & 0.964 & 0.855 & 0.943 & 0.996
    \end{tabular}
    \captionof{table}{}
    \label{tbl:all}
\end{figure}

Looking at the full picture, I realized that while this conclusion of watching orders can be held starting from the simulated likeability, but just like the naive approach, it only approximate the likeabilities. The custom prior method is the only that will truly reflect my personal perception of the quality of these videos, and at higher sample counts, even the smallest changes in likeability values will be significant.

This project has been both entertaining to research, and also applicable in a lot of areas that I will be facing in the future. In the scope of this analysis, I can use various prior distributions to model to model each genre of videos that I'll watch, saving me time. I can also use it to find the best book online given the ratings, or select the most favorable bowling place given user reviews, the five methods offer me a spectrum of techniques to statistically analyze the problem. For future studies, it is likely that I will be including the view counts and creating a more inclusive metric to account for videos that does not follow my main assumption --- that people are rating the videos solely based on its quality. This may reduce the  impact of dislike-bombing or view-botting on YouTube and other video sharing platforms. Nevertheless, this has been a worthwhile exploration.

% bib
\newpage
%\nocite{*}
\printbibliography


\newpage
\appendix
\counterwithin{figure}{section}
\counterwithin{table}{section}
\section{Figures}

\begin{figure}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c}
        & 5 likes, 1 dislike & 50, 10 & 500, 100 & 5000, 1000 & 50000, 10000 \\
        \hline
        \hline
        Naive likeability (3dp) & 0.833 & 0.833 & 0.833 & 0.833 & 0.833\\ \hline
        Statistical likeability (3dp) & 0.750 & 0.823 & 0.832 & 0.833 & 0.833\\ \hline
        Difference (3dp) & 0.083 & 0.011 & 0.001 & 0.000 & 0.000
    \end{tabular}
    \captionof{table}{Increase in accuracy of naive method as information size increases}
    \label{apd:acc}
\end{figure}


\begin{figure}[H]
    \begin{pythonln}
import random

def simulate_occurrence(likeability):
    occurrences = 0
    for _ in 0..sample_size:
        likes = 0
        for _ in 0..trials:
            if random() <= likeability:
                likes += 1
            occurrences += likes

    return occurrences
    \end{pythonln}
    % bruh this cant be highlighted using python lmao
    \caption{Implementation of the simulate\_occurrence function with pseudocode}
    \label{apd:sim_occ}
\end{figure}

\begin{figure}[H]
    \begin{pythonln}
from scipy.integrate import quad

def likeability(rolls, prior):
    priors = [...]
    likelihoods = [...]
    evidences = [...]

    priors[0] = prior
    mean = quad(lambda t: t * priors[0](t), 0, 1)

    # exponential time due to recursion
    for index in 0..len(rolls):
        is_like = rolls[index] == 'L'
        if is_like:
            likelihoods[index] = lambda t: t
        else:
            likelihoods[index] = lambda t: 1 - t

        evidences[index] = quad(lambda t: likelihoods[i](t) * priors[i](t),
                               0, 1)
        priors[index+1] = lambda t: likelihoods[i](t) * priors[i](t) \
                                / evidences[i]

        mean = quad(t: t * priors[i+1](t), 0, 1)

    return mean
    \end{pythonln}
    \caption{The algorithm to compute the Bayesian likeability given an initial prior probability density function}
    \label{apd:algo}
\end{figure}

\begin{figure}[H]
    \paragraph{Proof}

    \caption{Proof of the N-Likes Generalization}
    \label{eq:nlikeproof}
\end{figure}

\end{document}
